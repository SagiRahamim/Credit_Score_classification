<html>
<head>
<title>Multi_Classification_Credit_Score.ipynb</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<style type="text/css">
.s0 { color: #808080;}
.s1 { color: #a9b7c6;}
.s2 { color: #cc7832;}
.s3 { color: #6a8759;}
.s4 { color: #6897bb;}
</style>
</head>
<body bgcolor="#2b2b2b">
<table CELLSPACING=0 CELLPADDING=5 COLS=1 WIDTH="100%" BGCOLOR="#606060" >
<tr><td><center>
<font face="Arial, Helvetica" color="#000000">
Multi_Classification_Credit_Score.ipynb</font>
</center></td></tr></table>
<pre><span class="s0">#%% md 
</span><span class="s1">**Multi Classification problem** (Credit Score classification) 
 
* Exploratory Data Analysis 
* Data Preprocessing 
* Feature Engineering 
 
 
* Prediction algorithms: 
    1. Fully connected neural network (Pytorch &amp; Optuna Libraries). 
    2. Random Forest. 
    3. K-nearest neighbors (Knn). 
    4. Histogram-based Gradient Boosting Classification Tree. 
    5. XGboost-eXtreme Gradient Boosting. 
    6. Ensemble (weighted majority vote). 
</span><span class="s0">#%% 
</span><span class="s2">import </span><span class="s1">pandas </span><span class="s2">as </span><span class="s1">pd</span>
<span class="s2">import </span><span class="s1">numpy </span><span class="s2">as </span><span class="s1">np</span>
<span class="s2">import </span><span class="s1">seaborn </span><span class="s2">as </span><span class="s1">sns</span>
<span class="s2">from </span><span class="s1">tqdm </span><span class="s2">import </span><span class="s1">tqdm</span>
<span class="s2">import </span><span class="s1">matplotlib.pyplot </span><span class="s2">as </span><span class="s1">plt</span>
<span class="s2">import </span><span class="s1">torch</span>
<span class="s2">from </span><span class="s1">torch </span><span class="s2">import </span><span class="s1">nn</span>
<span class="s2">from </span><span class="s1">sklearn.preprocessing </span><span class="s2">import </span><span class="s1">PowerTransformer</span>
<span class="s2">from </span><span class="s1">sklearn.ensemble </span><span class="s2">import </span><span class="s1">RandomForestClassifier</span><span class="s2">,</span><span class="s1">AdaBoostClassifier</span><span class="s2">,</span><span class="s1">\</span>
    <span class="s1">HistGradientBoostingClassifier</span><span class="s2">,</span><span class="s1">GradientBoostingClassifier</span>
<span class="s2">from </span><span class="s1">sklearn.model_selection </span><span class="s2">import </span><span class="s1">StratifiedKFold</span>
<span class="s2">from </span><span class="s1">sklearn.model_selection </span><span class="s2">import </span><span class="s1">cross_val_score</span>
<span class="s2">from </span><span class="s1">sklearn.neighbors </span><span class="s2">import </span><span class="s1">KNeighborsClassifier</span>
<span class="s2">from </span><span class="s1">sklearn.pipeline </span><span class="s2">import </span><span class="s1">make_pipeline</span>
<span class="s2">from </span><span class="s1">xgboost </span><span class="s2">import </span><span class="s1">XGBClassifier</span>
<span class="s2">from </span><span class="s1">imblearn.over_sampling </span><span class="s2">import </span><span class="s1">ADASYN</span><span class="s2">,</span><span class="s1">RandomOverSampler</span>
<span class="s2">from </span><span class="s1">sklearn.metrics </span><span class="s2">import </span><span class="s1">classification_report</span><span class="s2">,</span><span class="s1">confusion_matrix</span><span class="s2">,</span><span class="s1">ConfusionMatrixDisplay</span>
<span class="s1">%matplotlib inline</span>
<span class="s0">#%% 
</span><span class="s1">pd.set_option(</span><span class="s3">'display.max_columns'</span><span class="s2">,</span><span class="s4">35</span><span class="s1">)</span>
<span class="s1">train_path = </span><span class="s3">r'train.csv'</span>
<span class="s1">test_path = </span><span class="s3">r'test.csv'</span>
<span class="s1">train_df = pd.read_csv(train_path</span><span class="s2">, </span><span class="s1">low_memory=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s1">test_df = pd.read_csv(test_path)</span>
<span class="s0">#%% 
</span><span class="s1">test_df.head()</span>
<span class="s0">#%% 
</span><span class="s1">train_df.shape</span>
<span class="s0">#%% 
</span><span class="s1">train_df.head()</span>
<span class="s0">#%% md 
</span><span class="s1">Data have invalid values, e.g. &quot;_&quot; in the Changed Credit Limit feature, and &quot;-&quot; in the Age column, both in row index 2. 
</span><span class="s0">#%% md 
</span><span class="s1">Dropping irrelevant columns: 
ID, Customer_ID, Name, and SSN are irrelevant for the prediction model, 
But I will keep Customer_ID (a feature that didn't suffer from missing values) 
that may be used as an indicator for filling missing\invalid values. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.drop([</span><span class="s3">'ID'</span><span class="s2">,</span><span class="s3">'Name'</span><span class="s2">,</span><span class="s3">'SSN'</span><span class="s1">]</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Before exploring those mix type columns and fixing that issue, let's look at the Null ratio per column, 
why? for example if the feature has 90% missing value and there isn't technique to fill the missing values-&gt; 
stay with 10K instances-&gt; It's reasonable That the feature will be irrelevant, but not for sure, 
e.g. can use the feature as sub-model. 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">na_ratio_plot(df=train_df):</span>

    <span class="s1">sns.displot(df.isna().melt(value_name=</span><span class="s3">'Missing_data'</span><span class="s2">,</span><span class="s1">var_name=</span><span class="s3">'Features'</span><span class="s1">)\</span>
                <span class="s2">,</span><span class="s1">y=</span><span class="s3">'Features'</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Missing_data'</span><span class="s2">,</span><span class="s1">multiple=</span><span class="s3">'fill'</span><span class="s2">,</span><span class="s1">aspect=</span><span class="s4">9</span><span class="s1">/</span><span class="s4">8</span><span class="s1">)</span>

<span class="s1">print(train_df.isna().mean()[train_df.isna().mean()&gt;</span><span class="s4">0</span><span class="s1">])</span>
<span class="s1">na_ratio_plot()</span>
<span class="s0">#%% md 
</span><span class="s1">The maximum Na Ratio per column is ~0.15-&gt; not too high. Fill null is needed. 
</span><span class="s0">#%% md 
</span><span class="s1">Let's see if the target labels ratios are balanced. 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">target_ratio(df=train_df</span><span class="s2">,</span><span class="s1">target=</span><span class="s3">'Credit_Score'</span><span class="s1">):</span>

    <span class="s2">if not </span><span class="s1">target:</span>
        <span class="s1">plt.pie(df.value_counts()</span><span class="s2">,</span><span class="s1">labels=df.value_counts()</span>
                <span class="s1">.index</span><span class="s2">,</span><span class="s1">autopct=</span><span class="s3">'%.0f%%'</span><span class="s1">)</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">plt.pie(df[target].value_counts()</span><span class="s2">,</span><span class="s1">labels=df[target]</span>
                <span class="s1">.value_counts().index</span><span class="s2">,</span><span class="s1">autopct=</span><span class="s3">'%.0f%%'</span><span class="s1">)</span>

<span class="s1">target_ratio()</span>
<span class="s0">#%% md 
</span><span class="s1">I will refer to that for each prediction model before training. 
</span><span class="s0">#%% md 
</span>

<span class="s1">D-type per column. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.dtypes</span>
<span class="s0">#%% md 
</span><span class="s1">Describe features: 
 
-Interest_Rate:Represents the interest rate on credit card. 
-Num_of_Loan: Represents the number of loans taken from the bank. 
-Dealy_from_due_date: Represents the average number of days delayed from the payment date. 
-Num_of_Delayed_Payment: Represents the average 
  number of payments delayed by a person. 
-Changed_Credit_Limit: Represents the percentage 
  change in credit card limit. 
-Num_Credit_Inquiries: Represents the number of credit card inquiries. 
-Credit_Mix: Represents the classification of the mix of credits. 
-Outstanding_Debt :Represents the remaining debt to be paid (in USD). 
-Credit_Utilization_Ratio: Represents the utilization ratio of credit card. 
-Credit_History_Age: Represents the age of credit history of the person. 
-Payment_of_Min_Amount: Represents whether only the minimum amount was paid by the person. 
</span><span class="s0">#%% md 
</span>
<span class="s1">Drop duplicated rows (if having...). 
</span><span class="s0">#%% 
</span><span class="s1">train_df.drop_duplicates(inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Removing invalid characters from mix-type columns that need to be numeric values with help of REGEX 
(Regular Expression) and converting the d-type of the column. 
</span><span class="s0">#%% 
</span><span class="s1">mix_type_num_col = [</span><span class="s3">'Age'</span><span class="s2">, </span><span class="s3">'Annual_Income'</span><span class="s2">, </span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span>
                    <span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'Changed_Credit_Limit'</span><span class="s2">,</span>
                    <span class="s3">'Outstanding_Debt'</span><span class="s2">, </span><span class="s3">'Amount_invested_monthly'</span><span class="s2">, </span><span class="s3">'Monthly_Balance'</span><span class="s1">]</span>

<span class="s2">def </span><span class="s1">set_numeric_columns(features</span><span class="s2">,</span><span class="s1">df=</span><span class="s2">None</span><span class="s1">):</span>

    <span class="s1">df[features]=df[features].apply(</span><span class="s2">lambda </span><span class="s1">x: x.replace(</span><span class="s3">'_'</span><span class="s2">,</span><span class="s3">''</span><span class="s2">,</span><span class="s1">regex=</span><span class="s2">True</span><span class="s1">) )</span>
    <span class="s1">df[features]=df[features].apply(</span><span class="s2">lambda </span><span class="s1">x: x.str.strip())</span>
    <span class="s1">df[features]=df[features].apply(</span><span class="s2">lambda </span><span class="s1">x: x.replace(</span><span class="s3">''</span><span class="s2">,</span><span class="s1">np.nan))</span>
<span class="s0"># Convert numeric columns dtypes.</span>
    <span class="s1">df[features[</span><span class="s4">1</span><span class="s1">:]]=df[features[</span><span class="s4">1</span><span class="s1">:]].astype(</span><span class="s3">'float32'</span><span class="s1">)</span>
    <span class="s1">df[features[</span><span class="s4">0</span><span class="s1">]]=df[features[</span><span class="s4">0</span><span class="s1">]].astype(</span><span class="s3">'int32'</span><span class="s1">)</span>

<span class="s1">set_numeric_columns(mix_type_num_col</span><span class="s2">,</span><span class="s1">df=train_df)</span>
<span class="s0">#%% md 
</span><span class="s1">Checking d-type per column and missing values after executing the set_numeric_columns function 
</span><span class="s0">#%% 
</span><span class="s1">print(train_df[mix_type_num_col].dtypes)</span>
<span class="s1">na_ratio_plot(df=train_df)</span>
<span class="s0">#%% md 
</span><span class="s1">Describing the data frame for exploring the Distribution and invalid values. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.describe()</span>
<span class="s0">#%% md 
</span><span class="s1">I will replace values if needed after explored each column values, I just write the replace methods per column. 
Suspect values in columns: 
Age -&gt; max 8698 replace method: back\forward per customer. 
Annual_Income-&gt; check if the outlier values are logical. 
Monthly_Inhand_Salary-&gt;check if the outlier values are logical. 
Num_Bank_Accounts-&gt; max 1798, min -1 replace method: back\forward per customer. 
Num_Credit_Card-&gt; max 1499 replace method backward\forward per customer. 
Interest_Rate-&gt; max 5797 replace method: mean per customer. 
Num_of_Loan-&gt; max 1496 replace method: per customer backward fill, if not having value-&gt; forward fill. 
Delay_from_due_date-&gt; min -5. 
Num_of_Delayed_Payment-&gt; max 4397 replace method: mean per customer. 
Num_Credit_Inquiries-&gt; max 2597 replace method: mean per customer. 
Outstanding_Debt-&gt;check if the outlier values are logical. 
Credit_Utilization_Ratio-&gt;check if the outlier values are logical. 
Total_EMI_per_month-&gt; max 82331 replace method: mean per customer. 
Amount_invested_monthly-&gt;check if the outlier values are logical. 
Monthly_Balance-&gt; ~3.3e+26 replace method: mean val per customer. 
Occupation-&gt; replace method: mode per customer. 
Credit_Mix-&gt; replace method: backward\forward per customer. 
</span><span class="s0">#%% md 
</span>
<span class="s1">Printing the object-type columns unique attribute -&gt;to understand the attributes. 
</span><span class="s0">#%% 
</span><span class="s1">[(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">x</span><span class="s2">}</span><span class="s3">:  </span><span class="s2">{</span><span class="s1">train_df[x].unique()</span><span class="s2">}</span><span class="s3">'</span><span class="s2">,</span><span class="s3">'-'</span><span class="s1">*</span><span class="s4">85</span><span class="s1">) </span><span class="s2">for </span><span class="s1">x </span><span class="s2">in</span><span class="s1">\</span>
 <span class="s1">train_df[[</span><span class="s3">'Occupation'</span><span class="s2">,</span><span class="s3">'Credit_Mix'</span><span class="s2">,</span><span class="s3">'Payment_Behaviour'</span><span class="s1">]]]</span>
<span class="s0">#%% md 
</span>
<span class="s1">Replacing invalid attributes to np.nan-&gt; I will build a Class that replaces all nan/invalid values using different methods. 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">replace_invalid_2_nan(df):</span>

    <span class="s1">_= {</span><span class="s3">'Occupation'</span><span class="s1">: </span><span class="s3">'_'</span><span class="s1">*</span><span class="s4">7</span><span class="s2">, </span><span class="s3">'Credit_Mix'</span><span class="s1">:</span><span class="s3">'_'</span><span class="s2">,</span><span class="s3">'Payment_Behaviour'</span><span class="s1">:</span><span class="s3">'!@9#%8'</span><span class="s1">}</span>
    <span class="s2">for </span><span class="s1">x </span><span class="s2">in </span><span class="s1">_.items():</span>
        <span class="s1">df[x[</span><span class="s4">0</span><span class="s1">]].replace(x[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">,</span><span class="s1">np.nan</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s1">replace_invalid_2_nan(train_df)</span>
<span class="s0">#%% md 
</span><span class="s1"># Feature engineering | Credit History Age 
*Creating a function Converts Credit_history_Age to numeric type-&gt;  Months sum representation. (will be used for new data to make a prediction)* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">convert_str_num(column</span><span class="s2">,</span><span class="s1">indicator</span><span class="s2">,</span><span class="s1">magnitude</span><span class="s2">,</span><span class="s1">df=train_df):</span>
    <span class="s1">i=indicator</span>
    <span class="s1">m=magnitude</span>
    <span class="s0"># set as a float for flexibility of the function.</span>
    <span class="s1">_=df[column].apply(</span><span class="s2">lambda </span><span class="s1">x: float(x.split(</span><span class="s3">' '</span><span class="s1">)[i[</span><span class="s4">0</span><span class="s1">]])*m[</span><span class="s4">0</span><span class="s1">]+</span>
                                 <span class="s1">float(x.split(</span><span class="s3">' '</span><span class="s1">)[i[</span><span class="s4">1</span><span class="s1">]])*m[</span><span class="s4">1</span><span class="s1">]</span>
                                <span class="s2">if </span><span class="s1">type(x)==str </span><span class="s2">else </span><span class="s1">x)</span>
    <span class="s2">return </span><span class="s1">_</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Credit_History_Age=convert_str_num(</span><span class="s3">'Credit_History_Age'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">0</span><span class="s2">,</span><span class="s4">3</span><span class="s1">]</span><span class="s2">,</span><span class="s1">[</span><span class="s4">12</span><span class="s2">,</span><span class="s4">1</span><span class="s1">])</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Credit_History_Age.head(</span><span class="s4">4</span><span class="s1">)</span>
<span class="s0">#%% md 
</span>
<span class="s1">Let's see correlation between numeric features. 
Checking now to see if the data has features with the same pattern(corr_value&gt;~0.98)-&gt; 
may not contribute to the prediction model because the features have the same pattern 
meaning one of them will not impact the prediction. 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">correlation_plot(df=train_df):</span>
    <span class="s1">plt.figure(figsize=[</span><span class="s4">12</span><span class="s2">,</span><span class="s4">8</span><span class="s1">])</span>
    <span class="s1">sns.heatmap(df.select_dtypes(exclude=</span><span class="s3">'object'</span><span class="s1">)</span>
                <span class="s1">.dropna().corr()</span><span class="s2">,</span><span class="s1">annot=</span><span class="s2">True,</span>
                <span class="s1">fmt=</span><span class="s3">'.1f'</span><span class="s2">,</span><span class="s1">linewidth=</span><span class="s4">.2</span><span class="s1">)</span>

<span class="s1">correlation_plot()</span>
<span class="s0">#%% md 
</span><span class="s1">I will check again after filling\replacing values. 
</span><span class="s0">#%% md 
</span>
<span class="s1">**Creating a function that returns scatter\histogram (with continuous density(using Gaussian kernel-&gt;using seaborn KDE method) plot by categorical indicator.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">plots_by_categ(feature1</span><span class="s2">,</span><span class="s1">plot_type=</span><span class="s3">'hist'</span><span class="s2">,</span>
                   <span class="s1">feature2=</span><span class="s3">'Credit_Score'</span><span class="s2">,</span>
                   <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">multi_class=</span><span class="s2">True,</span><span class="s1">bins=</span><span class="s4">30</span><span class="s1">):</span>

    <span class="s2">if </span><span class="s1">df[feature1].nunique()&lt;</span><span class="s4">30</span><span class="s1">:</span>
        <span class="s1">bins=df[feature1].nunique()</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">multi_class:</span>
        <span class="s1">_=df[feature2].unique().tolist()</span>
        <span class="s1">col=len(_)</span>

        <span class="s2">if </span><span class="s1">df[feature1].dtype!=</span><span class="s3">'O'</span><span class="s1">:</span>
            <span class="s1">col+=</span><span class="s4">1</span>

        <span class="s1">fig</span><span class="s2">,</span><span class="s1">axes=plt.subplots(</span><span class="s4">1</span><span class="s2">,</span><span class="s1">col</span><span class="s2">,</span><span class="s1">sharey=</span><span class="s3">'none'</span><span class="s2">,</span><span class="s1">figsize=[</span><span class="s4">14</span><span class="s2">,</span><span class="s4">5</span><span class="s1">])</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">plot_type.lower()==</span><span class="s3">'scatter'</span><span class="s1">:</span>

        <span class="s2">if </span><span class="s1">multi_class:</span>
            <span class="s1">fig.suptitle(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">feature2</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

            <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">v </span><span class="s2">in </span><span class="s1">enumerate(_):</span>
                <span class="s1">sns.scatterplot(y=(df[feature1][df[feature2]==v]).dropna()</span><span class="s2">,</span>
                                <span class="s1">x=(df[feature1][df[feature2]==v]).dropna().index</span><span class="s2">,</span>
                                <span class="s1">ax=axes[i])</span>
                <span class="s1">axes[i].set_title(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">v</span><span class="s2">}\n{</span><span class="s1">feature2</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">plt.figure(figsize=[</span><span class="s4">4</span><span class="s2">,</span><span class="s4">3</span><span class="s1">])</span>
            <span class="s1">sns.scatterplot(x=df[feature1]</span><span class="s2">,</span><span class="s1">y=df[feature2])</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">multi_class:</span>
            <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">value </span><span class="s2">in </span><span class="s1">enumerate(_):</span>

                <span class="s2">if </span><span class="s1">df[feature1].dtype!=</span><span class="s3">'O'</span><span class="s1">:</span>
                    <span class="s1">i+=</span><span class="s4">1</span>

                    <span class="s2">if </span><span class="s1">i==</span><span class="s4">1</span><span class="s1">:</span>
                        <span class="s1">sns.kdeplot(data=df[[feature1</span><span class="s2">,</span><span class="s1">feature2]]</span><span class="s2">,</span>
                                    <span class="s1">x=feature1</span><span class="s2">,</span><span class="s1">hue=feature2</span><span class="s2">,</span>
                                    <span class="s1">ax=axes[</span><span class="s4">0</span><span class="s1">])</span>

                <span class="s1">sns.histplot((df[feature1][df[feature2]==value]).dropna()</span><span class="s2">,</span>
                             <span class="s1">bins=bins</span><span class="s2">,</span><span class="s1">ax=axes[i]</span><span class="s2">,</span><span class="s1">kde=</span><span class="s2">True</span><span class="s1">)</span>

                <span class="s1">axes[i].set_title(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">value</span><span class="s2">} {</span><span class="s1">feature2</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">plt.figure(figsize=[</span><span class="s4">4</span><span class="s2">,</span><span class="s4">4</span><span class="s1">])</span>
            <span class="s1">sns.set_style(</span><span class="s3">&quot;whitegrid&quot;</span><span class="s2">, </span><span class="s1">{</span><span class="s3">'axes.grid' </span><span class="s1">: </span><span class="s2">False</span><span class="s1">})</span>
            <span class="s1">sns.histplot(data=df[[feature1</span><span class="s2">,</span><span class="s1">feature2]]</span><span class="s2">,</span>
                         <span class="s1">x=feature1</span><span class="s2">,</span><span class="s1">bins=bins</span><span class="s2">,</span><span class="s1">hue=feature2)</span>

<span class="s0">#%% md 
</span><span class="s1"># Payment of Min Amount 
</span><span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Payment_of_Min_Amount'</span><span class="s2">,</span><span class="s1">multi_class=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Payment_of_Min_Amount'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">In the Payment_of_Min_Amount column the value NM-Not Much-&gt; valid. 
</span><span class="s0">#%% md 
</span><span class="s1">**Creating a function that calculates outliers using the IQR method.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">iqr_method(feature</span><span class="s2">,</span><span class="s1">df=train_df):</span>
    <span class="s1">q1=df[feature].quantile(</span><span class="s4">0.25</span><span class="s1">)</span>
    <span class="s1">q3=df[feature].quantile(</span><span class="s4">0.75</span><span class="s1">)</span>
    <span class="s1">iqr=q3-q1</span>
    <span class="s1">upper=q3+</span><span class="s4">2</span><span class="s1">*iqr</span>
    <span class="s1">lower=q1-</span><span class="s4">2</span><span class="s1">*iqr</span>
    <span class="s2">return </span><span class="s1">[lower</span><span class="s2">,</span><span class="s1">upper]</span>
<span class="s0">#%% md 
</span><span class="s1">**Creating a function that returns std, mean, max, and min per customer.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">describe_per_id(feature</span><span class="s2">,</span><span class="s1">indicator=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span>
                    <span class="s1">method=(</span><span class="s3">'min'</span><span class="s2">,</span><span class="s3">'quantile'</span><span class="s2">,</span><span class="s3">'std'</span><span class="s2">,</span><span class="s3">'mean'</span><span class="s2">,</span><span class="s3">'max'</span><span class="s1">)</span><span class="s2">,</span>
                    <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">sort_by=</span><span class="s3">'std'</span><span class="s2">,</span><span class="s1">plot=</span><span class="s2">False,</span><span class="s1">kind=</span><span class="s3">'line'</span><span class="s1">):</span>

    <span class="s1">describe_df=df.groupby(indicator)[feature]\</span>
        <span class="s1">.agg(method).sort_values(by=sort_by)\</span>
        <span class="s1">.reset_index(drop=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">plot:</span>
        <span class="s1">sns.relplot(data=describe_df</span><span class="s2">,</span><span class="s1">kind=kind)</span>
        <span class="s1">plt.xlabel(indicator)</span>
        <span class="s1">plt.ylabel(feature)</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">return </span><span class="s1">describe_df</span>
<span class="s0">#%% md 
</span>
<span class="s1">**Creating a function that will help to explore the outliers, and return indicators per customer.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">get_indicators_df(check_feature</span><span class="s2">,</span><span class="s1">thresholds=</span><span class="s3">'iqr'</span><span class="s2">,</span>
                      <span class="s1">show_features=</span><span class="s2">False,</span><span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">indicator=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span>
                      <span class="s1">positive=</span><span class="s2">True,</span><span class="s1">return_df=</span><span class="s2">False,</span><span class="s1">return_indicator=</span><span class="s2">True,</span>
                      <span class="s1">only_na=</span><span class="s2">False,</span><span class="s1">spectrum=</span><span class="s2">False,</span><span class="s1">return_na=</span><span class="s2">False,</span>
                      <span class="s1">return_egg_plot=</span><span class="s2">False,</span><span class="s1">plot_kind=</span><span class="s3">'line'</span><span class="s2">,</span>
                      <span class="s1">cus_std_threshold=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s2">if </span><span class="s1">return_df </span><span class="s2">or </span><span class="s1">return_egg_plot:</span>
        <span class="s1">return_indicator=</span><span class="s2">False</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">thresholds==</span><span class="s3">'iqr'</span><span class="s1">:</span>

        <span class="s2">if </span><span class="s1">df[check_feature].dtype!=(</span><span class="s3">'object' </span><span class="s2">or </span><span class="s3">'string' </span><span class="s2">or </span><span class="s3">'categorical'</span><span class="s1">):</span>
            <span class="s1">thresholds=iqr_method(check_feature)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">show_features </span><span class="s2">is True</span><span class="s1">:</span>
        <span class="s1">show_features=df.columns</span>

    <span class="s2">elif </span><span class="s1">show_features </span><span class="s2">is False</span><span class="s1">:</span>
        <span class="s1">show_features=[indicator</span><span class="s2">,</span><span class="s1">check_feature]</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">df[check_feature].isna().sum()&gt;</span><span class="s4">1</span><span class="s1">:</span>
        <span class="s1">print(</span><span class="s3">f'The feature </span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">having </span><span class="s2">{</span><span class="s1">df[check_feature].isna().sum()</span><span class="s2">} </span><span class="s3">Na'</span><span class="s1">)</span>
        <span class="s0"># if (return_na and return_only_na_indicator) is False:</span>
        <span class="s0">#     print(f'The feature {check_feature} having {df[check_feature].isna().sum()} na')</span>
        <span class="s0">#     intype=input(f&quot;The feature {check_feature} having {df[check_feature].isna().sum()} na-&gt;\nEnter by the following option:\nna-&gt;to return only na indicator, \nyes-&gt;to including na, \nno-&gt;to not including na.&quot;)</span>
        <span class="s0">#     if intype.strip(' ').lower()=='no':</span>
        <span class="s0">#         return_na=False</span>
        <span class="s0">#     elif intype.strip(' ').lower()=='na':</span>
        <span class="s0">#         return_only_na_indicator=True</span>
        <span class="s0">#     else:</span>
        <span class="s0">#         return_na=True</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if not </span><span class="s1">only_na:</span>

        <span class="s2">if </span><span class="s1">df[check_feature].dtype != (</span><span class="s3">'object' </span><span class="s2">or </span><span class="s3">'string' </span><span class="s2">or </span><span class="s3">'categorical'</span><span class="s1">):</span>
            <span class="s2">if </span><span class="s1">type(thresholds) == list:</span>
                <span class="s2">if </span><span class="s1">len(thresholds) != </span><span class="s4">2</span><span class="s1">:</span>
                    <span class="s2">return </span><span class="s3">'insert 2 values for threshold'</span>
                <span class="s2">elif </span><span class="s1">spectrum:</span>
                    <span class="s1">split_df = df.query(</span><span class="s3">f'((</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&gt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}</span><span class="s3">) '</span>
                                        <span class="s3">f'&amp; (</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">}</span><span class="s3">))'</span><span class="s1">)[indicator]</span>

                <span class="s2">elif </span><span class="s1">positive:</span>
                    <span class="s1">split_df = df.query(</span><span class="s3">f'(((</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}</span><span class="s3">) '</span>
                                        <span class="s3">f'| (</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&gt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">}</span><span class="s3">))'</span>
                                        <span class="s3">f'| (</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; 0))'</span><span class="s1">)[indicator]</span>

                <span class="s2">elif not </span><span class="s1">positive:</span>
                    <span class="s1">split_df = df.query(</span><span class="s3">f'((</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}</span><span class="s3">) '</span>
                                        <span class="s3">f'| (</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&gt; </span><span class="s2">{</span><span class="s1">thresholds[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">}</span><span class="s3">))'</span><span class="s1">)[indicator]</span>

            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">thresholds == </span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">split_df = df.query(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; 0'</span><span class="s1">)[indicator]</span>

                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s2">if </span><span class="s1">positive:</span>
                        <span class="s1">split_df = df.query(</span><span class="s3">f'(</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; </span><span class="s2">{</span><span class="s1">thresholds</span><span class="s2">}</span><span class="s3">) '</span>
                                            <span class="s3">f'| (</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&lt; 0)'</span><span class="s1">)[indicator]</span>


                    <span class="s2">elif not </span><span class="s1">positive:</span>
                        <span class="s1">split_df = df.query(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">&gt; </span><span class="s2">{</span><span class="s1">thresholds</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)[indicator]</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s0"># not included all dtypes, but it's suitable for the current data frame.</span>
            <span class="s2">if </span><span class="s1">df[check_feature].dtype == (</span><span class="s3">'object' </span><span class="s2">or </span><span class="s3">'string' </span><span class="s2">or </span><span class="s3">'categorical'</span><span class="s1">):</span>
                <span class="s1">print(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">Feature dtype isn't numeric-&gt; Return Na indicators.&quot;</span><span class="s1">)</span>
                <span class="s1">split_df = df[indicator][df[check_feature].isna()]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">print(</span><span class="s3">f'The function suitable with the following dtypes:</span><span class="s2">\ 
                </span><span class="s3">numerics dtypes,object,string,and categorical-&gt;'</span>
                             <span class="s3">f' </span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">dtype is </span><span class="s2">{</span><span class="s1">df[check_feature].dtype</span><span class="s2">}</span><span class="s3">' </span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">split_df = df[indicator][df[check_feature].isna()]</span>

    <span class="s2">if </span><span class="s1">cus_std_threshold </span><span class="s2">is not False</span><span class="s1">:</span>
        <span class="s1">split_df=split_df[split_df.isin((df.loc[:</span><span class="s2">,</span><span class="s1">[indicator</span><span class="s2">,</span><span class="s1">check_feature]]</span>
                                         <span class="s1">.groupby(indicator).agg(</span><span class="s3">'std'</span><span class="s1">))</span>
                                        <span class="s1">.query(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">}</span><span class="s3">'</span>
                                               <span class="s3">f'.abs()&gt;</span><span class="s2">{</span><span class="s1">cus_std_threshold</span><span class="s2">}</span><span class="s3">'</span><span class="s1">).index)]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">return_na:</span>
        <span class="s1">split_df = pd.concat([split_df</span><span class="s2">,</span><span class="s1">df.query(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">}</span><span class="s3">.isna()'</span><span class="s1">)[indicator]])</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">pass</span>

    <span class="s2">if </span><span class="s1">return_egg_plot:</span>
        <span class="s1">describe_per_id(feature=check_feature </span><span class="s2">,</span><span class="s1">indicator=indicator</span><span class="s2">,</span>
                        <span class="s1">df=df[show_features][df[indicator].isin(split_df.unique())]</span><span class="s2">,</span>
                        <span class="s1">kind=plot_kind</span><span class="s2">,</span><span class="s1">plot=</span><span class="s2">True</span><span class="s1">)</span>

        <span class="s1">plt.title(</span><span class="s3">f'Describe </span><span class="s2">{</span><span class="s1">check_feature</span><span class="s2">} </span><span class="s3">per customer,Thresholds-&gt;</span><span class="s2">{</span><span class="s1">thresholds</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s2">elif </span><span class="s1">return_df &amp; return_indicator:</span>
        <span class="s2">return </span><span class="s1">df[check_feature][df[indicator].isin(split_df.unique().tolist())]</span><span class="s2">,</span><span class="s1">\</span>
               <span class="s1">split_df.index</span><span class="s2">, </span><span class="s1">split_df.tolist()</span>

    <span class="s2">elif </span><span class="s1">return_indicator:</span>
        <span class="s2">return </span><span class="s1">split_df.index.tolist()</span><span class="s2">, </span><span class="s1">split_df.tolist()</span>

    <span class="s2">elif </span><span class="s1">return_df:</span>
        <span class="s2">return </span><span class="s1">df[show_features][df[indicator].isin(split_df.unique().tolist())]</span>


<span class="s0">#%% md 
</span><span class="s1"># Num Bank Accounts 
</span><span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Creating a function for checking gaps each customer instances.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">gap_threshold(threshold</span><span class="s2">,</span><span class="s1">feature</span><span class="s2">,</span><span class="s1">instances=</span><span class="s2">False,</span>
                  <span class="s1">indicator=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s1">df=train_df):</span>
    <span class="s1">ind=[]</span>
    <span class="s1">ins=[]</span>

    <span class="s2">if </span><span class="s1">instances </span><span class="s2">is False</span><span class="s1">:</span>
        <span class="s1">instances=df.index.tolist()</span>
    <span class="s2">elif </span><span class="s1">type(instances) </span><span class="s2">is </span><span class="s1">str:</span>
        <span class="s2">if </span><span class="s1">instances.lower()==</span><span class="s3">'iqr'</span><span class="s1">:</span>
            <span class="s1">instances=get_indicators_df(feature</span><span class="s2">,</span><span class="s1">df=df)[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">tqdm(instances):</span>
        <span class="s1">per_cost_df=df.query(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">indicator</span><span class="s2">}</span><span class="s3">.isin(</span><span class="s2">{</span><span class="s1">[df[indicator].loc[i]]</span><span class="s2">}</span><span class="s3">)&quot;</span><span class="s1">)</span>
        <span class="s1">gap=(per_cost_df[feature].mode()-per_cost_df[feature].loc[i]).abs()[</span><span class="s4">0</span><span class="s1">]</span>
        <span class="s2">if </span><span class="s1">gap&gt;threshold:</span>
            <span class="s1">ins.append(i)</span>
            <span class="s1">ind.append(df[indicator].loc[i])</span>

    <span class="s2">return </span><span class="s1">ins</span><span class="s2">,</span><span class="s1">ind</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Num_Bank_Accounts.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">df=get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span>
                                                        <span class="s1">return_df=</span><span class="s2">True,</span>
                                                        <span class="s1">show_features=</span><span class="s2">True</span><span class="s1">))</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">train_df[</span><span class="s3">'Num_Bank_Accounts'</span><span class="s1">].median()</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">3</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">describe_per_id(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">df=get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span>
                                                         <span class="s1">return_df=</span><span class="s2">True</span><span class="s1">)).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">15</span><span class="s2">,</span><span class="s4">20</span><span class="s1">]</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">spectrum=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span>
                  <span class="s1">[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s3">'Type_of_Loan'</span><span class="s1">]</span><span class="s2">,</span>
                  <span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">The Num Bank Accounts feature is having negative values (E.g.-1)-&gt; It's unclearly if it needed to be 0 or 1. 
Still, my intuition says that the -1 value needed to be replaced with 0, 
since the loan has already been taken without a bank account, and the Loan Types are-&gt;Debt Con..., 
auto, not specified. for a student loan, I didn't get any conclusion from the loan type, 
but I assume that -1 value is a pattern mistake. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_Bank_Accounts.replace(-</span><span class="s4">1</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Set threshold with IQR method that returned an upper limit of 15. 
</span><span class="s0">#%% md 
</span><span class="s1">**Creating a function that adds to dictionary indicator and method per feature for filling\replacing 
 some features values, I will extract the dictionary values after exploring all features.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict={}</span>
<span class="s2">def </span><span class="s1">replace_dict_fun(feature</span><span class="s2">,</span><span class="s1">method</span><span class="s2">,</span><span class="s1">gap=</span><span class="s2">None,</span><span class="s1">thresholds=</span><span class="s3">'iqr'</span><span class="s2">,</span>
                     <span class="s1">feature_indicator=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s1">df=train_df</span><span class="s2">,</span>
                     <span class="s1">return_na=</span><span class="s2">False,</span><span class="s1">only_na=</span><span class="s2">False,</span><span class="s1">std_threshold=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s2">if </span><span class="s1">thresholds==</span><span class="s3">'iqr'</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">gap </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">replace_dict[feature]=[gap_threshold(gap</span><span class="s2">,</span><span class="s1">feature</span><span class="s2">,</span><span class="s1">instances=</span><span class="s3">'iqr'</span><span class="s2">,</span><span class="s1">df=df)</span><span class="s2">,</span><span class="s1">method]</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">replace_dict[feature]=[get_indicators_df(feature</span><span class="s2">,</span><span class="s1">df=df</span><span class="s2">,</span>
                                                     <span class="s1">indicator=feature_indicator</span><span class="s2">,</span>
                                                     <span class="s1">return_na=return_na</span><span class="s2">,</span><span class="s1">only_na=only_na)</span><span class="s2">,</span><span class="s1">method]</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s2">if </span><span class="s1">gap </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">replace_dict[feature]=[gap_threshold(gap</span><span class="s2">,</span><span class="s1">feature</span><span class="s2">,</span><span class="s1">df=df)</span><span class="s2">,</span><span class="s1">method]</span>

        <span class="s1">replace_dict[feature]=[get_indicators_df(feature</span><span class="s2">,</span><span class="s1">df=df</span><span class="s2">,</span><span class="s1">indicator=feature_indicator</span><span class="s2">,</span>
                                                 <span class="s1">thresholds=thresholds</span><span class="s2">,</span><span class="s1">return_na=return_na</span><span class="s2">,</span>
                                                 <span class="s1">only_na=only_na</span><span class="s2">,</span><span class="s1">cus_std_threshold=std_threshold)</span><span class="s2">,</span><span class="s1">method]</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Num_Bank_Accounts feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Occupation feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Occupation'</span><span class="s2">,</span><span class="s3">'mode'</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Age 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Age.describe()</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Age=train_df.Age.abs()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Age'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Age'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Age'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">I will extract the instances with invalid values per customer using the gap_threshold function (build above) 
and set the gap threshold to 1, gap above 1 is illogical that in one month get growth above one year. 
Linked instance values will replace illogic values. 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Age'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s2">,</span><span class="s1">gap=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">df=train_df)</span>
<span class="s0">#%% 
# '''Show that the iqr indicator are suitable for the task, checking all instances--&gt;'''</span>
<span class="s0"># len(replace_dict['Age'][0][0])==(len(gap_threshold(threshold=1,feature='Age',df=train_df)[0]) and len(get_indicators_df('Age')[0]))</span>
<span class="s0">#%% md 
</span>
<span class="s1"># Num Credit Card 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_Credit_Card.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_Credit_Card'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Num_Credit_Card'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">13</span><span class="s2">,</span><span class="s4">16</span><span class="s1">]</span><span class="s2">,</span><span class="s1">show_features=</span><span class="s2">True,</span>
                  <span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">spectrum=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">The data has illogical values, e.g., interest rate:2123, num bank accounts:1349, et al. 
</span><span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">5</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Num_Credit_Card feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s2">,</span><span class="s1">std_threshold=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Interest Rate 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Interest_Rate.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Interest_Rate'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Interest_Rate'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Interest_Rate'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Interest_Rate'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">1</span><span class="s2">,</span><span class="s4">48</span><span class="s1">]</span><span class="s2">,</span><span class="s1">show_features=</span><span class="s2">True,</span><span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">It also seems to be a mistake because by looking at other features: Num_of_Loan, Delay_from_due_date, 
Total_EMI_per_month-&gt;  we can write a function with criteria that will check all criteria. 
For example: If a Customer has a good credit score it's illogical that he will get a high-interest rate. 
The Spectrum of Credit card interest rates is about ~5%-~30%. 
I assume all values above 44 are invalid and will replace them with back-forward values. 
</span><span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Interest_Rate feature to replace_dict dictionary.** 
 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Interest_Rate'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s2">,</span><span class="s1">std_threshold=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Num of Loan 1/2 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_of_Loan.describe()</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Replacing -100 values to Na. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_of_Loan.replace(-</span><span class="s4">100</span><span class="s2">,</span><span class="s1">np.nan</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_of_Loan'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Num_of_Loan'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">10</span><span class="s2">,</span><span class="s4">22</span><span class="s1">]</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">spectrum=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Type of Loan 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Type_of_Loan.unique()[:</span><span class="s4">8</span><span class="s1">]</span>
<span class="s0">#%% md 
</span><span class="s1">Removing 'and' to avoid duplicated loan types. 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Type_of_Loan=train_df.Type_of_Loan.str.replace(</span><span class="s3">'and'</span><span class="s2">,</span><span class="s3">''</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Checking if NaN indicator that customer doesn't have loans. 
</span><span class="s0">#%% 
</span><span class="s1">loan_na=get_indicators_df(</span><span class="s3">'Type_of_Loan'</span><span class="s2">,</span>
                          <span class="s1">show_features=[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s3">'Type_of_Loan'</span><span class="s1">]</span><span class="s2">,</span>
                          <span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">only_na=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s1">cus_loan_0_100=list(loan_na.query(</span><span class="s3">'0&lt;Num_of_Loan&lt;100'</span><span class="s1">).Customer_ID.unique())</span>
<span class="s1">train_df.query(</span><span class="s3">f'Customer_ID.isin(</span><span class="s2">{</span><span class="s1">cus_loan_0_100</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)\</span>
    <span class="s1">[[</span><span class="s3">'Type_of_Loan'</span><span class="s2">,</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s1">]]</span>
<span class="s0">#%% 
</span><span class="s1">loan_na.isna().sum()</span>
<span class="s0">#%% 
</span><span class="s1">len(gap_threshold(</span><span class="s4">11</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span>
                  <span class="s1">df=loan_na)[</span><span class="s4">0</span><span class="s1">])==loan_na[loan_na.Num_of_Loan&gt;</span><span class="s4">0</span><span class="s1">].Num_of_Loan.shape[</span><span class="s4">0</span><span class="s1">]</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">loan_na</span><span class="s2">,</span><span class="s1">cus_loan_0_100</span>
<span class="s0">#%% md 
</span><span class="s1"># Feature engineering | Type of loan 
*Feature engineering -&gt; splitting the list of the loan types -&gt;replacing the values with the sum of the loan types-&gt; one hot encoding method.* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">convert_loans_type(df=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s1">unique_loans_type = []</span>
    <span class="s1">col = []</span>

    <span class="s1">[unique_loans_type.extend(df.loc[:</span><span class="s2">, </span><span class="s3">'Type_of_Loan'</span><span class="s1">].str.split(</span><span class="s3">','</span><span class="s1">)</span>
                              <span class="s1">.str.get(i).str.strip().unique()</span>
                              <span class="s1">.tolist()) </span><span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">9</span><span class="s1">)]</span>

    <span class="s1">unique_loans_type = list(set(unique_loans_type))</span>
<span class="s0"># '''convert object to columns'''</span>
    <span class="s1">_ = np.zeros((df.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">, </span><span class="s1">len(unique_loans_type)))</span>
    <span class="s1">get_dummies = pd.DataFrame(_</span><span class="s2">, </span><span class="s1">columns=unique_loans_type)</span>

    <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">tqdm(range(</span><span class="s4">9</span><span class="s1">)):</span>
        <span class="s1">col = df.loc[:</span><span class="s2">, </span><span class="s3">'Type_of_Loan'</span><span class="s1">].str.split(</span><span class="s3">','</span><span class="s1">).str.get(n).str.strip().unique().tolist()</span>
        <span class="s1">get_dummies.loc[:</span><span class="s2">, </span><span class="s1">col] = get_dummies.loc[:</span><span class="s2">, </span><span class="s1">col] + \</span>
                                  <span class="s1">pd.get_dummies(df.loc[:</span><span class="s2">, </span><span class="s3">'Type_of_Loan'</span><span class="s1">]</span>
                                                 <span class="s1">.str.split(</span><span class="s3">','</span><span class="s1">).str.get(n)</span>
                                                 <span class="s1">.str.strip())</span>

    <span class="s1">df.rename(columns={</span><span class="s3">'Credit_History_Age'</span><span class="s1">: </span><span class="s3">'Credit_Months_History_Age'</span><span class="s1">})</span>
    <span class="s1">df = pd.concat([df</span><span class="s2">, </span><span class="s1">get_dummies]</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">df.drop([</span><span class="s3">'Type_of_Loan'</span><span class="s1">]</span><span class="s2">, </span><span class="s1">inplace=</span><span class="s2">True, </span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>
    <span class="s1">df.dropna(axis=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">how=</span><span class="s3">'all'</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">df</span>

<span class="s1">train_df=convert_loans_type(df=train_df)</span>
<span class="s0">#%% 
</span><span class="s1">(train_df.iloc[:</span><span class="s2">,</span><span class="s1">-</span><span class="s4">9</span><span class="s1">:].sum(axis=</span><span class="s4">1</span><span class="s1">)!=train_df.Num_of_Loan).sum()\</span>
<span class="s1">==len(get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">])</span>
<span class="s0">#%% md 
</span><span class="s1">*The sum of the types of loans will fill the NA.* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">fill_na_loan(df=train_df):</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">df=df</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]:</span>
        <span class="s1">df.loc[i</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s1">]=int(df.loc[i</span><span class="s2">,</span><span class="s3">'Home Equity Loan'</span><span class="s1">:].sum())</span>
    <span class="s2">return </span><span class="s1">df</span>

<span class="s1">train_df=fill_na_loan(df=train_df)</span>
<span class="s0">#%% md 
</span><span class="s1"># Num of Loan 2/2 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_of_Loan.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">df=train_df)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Delay from due date 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Delay_from_due_date.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Delay_from_due_date'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Delay_from_due_date'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Delay_from_due_date'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Delay_from_due_date'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span>
                  <span class="s1">show_features=[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_Bank_Accounts'</span><span class="s2">,</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span>
                                 <span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s3">'Delay_from_due_date'</span><span class="s1">]</span><span class="s2">,</span>
                  <span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">positive=</span><span class="s2">False</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Delay_from_due_date column having negative values-&gt; I will not change that because it's maybe indicative of early payment. 
</span><span class="s0">#%% md 
</span><span class="s1">The values are logical -&gt;max std per customer is ~4, 
will prove by checking the following month's gap if gap&gt;31 -&gt;illogical value. 
Why? 
31 days are the maximum gap between consecutive months. 
</span><span class="s0">#%% md 
</span>
<span class="s1">**Creating a function that checks gaps between instances per customer.** 
</span><span class="s0">#%% 
</span><span class="s1">train_df.loc[</span><span class="s4">1</span><span class="s1">:</span><span class="s2">,</span><span class="s3">'Delay_from_due_date'</span><span class="s1">].to_numpy()</span>
<span class="s2">def </span><span class="s1">check_gaps(feature</span><span class="s2">,</span><span class="s1">valid_gap </span><span class="s2">,</span><span class="s1">indicator=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span>
               <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">back_forward=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s1">indicator_to_invalid={}</span>
    <span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">tqdm(df[indicator].unique().tolist()):</span>
        <span class="s1">_=(df.loc[df.index[df[indicator]==i]</span><span class="s2">,</span><span class="s1">feature]).to_numpy()</span>

        <span class="s2">if </span><span class="s1">back_forward:</span>
            <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">,</span><span class="s4">7</span><span class="s1">):</span>
                <span class="s1">gap=abs(_[n]-_[n+</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s1">gap_2=abs(_[n]-_[n-</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s2">if </span><span class="s1">gap&gt;valid_gap </span><span class="s2">and </span><span class="s1">gap_2&gt;valid_gap:</span>
                    <span class="s1">indicator_to_invalid[i]={n:gap}</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s2">for </span><span class="s1">n </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">7</span><span class="s1">):</span>
                <span class="s1">gap=abs(_[n]-_[n+</span><span class="s4">1</span><span class="s1">])</span>
                <span class="s2">if </span><span class="s1">gap&gt;valid_gap:</span>
                    <span class="s1">indicator_to_invalid[i]={n+</span><span class="s4">1</span><span class="s1">:gap}</span>

    <span class="s2">if </span><span class="s1">indicator_to_invalid=={}:</span>
        <span class="s2">return </span><span class="s1">print(</span><span class="s3">f'All gaps between the Consecutive instances per </span><span class="s2">{</span><span class="s1">indicator</span><span class="s2">} </span><span class="s3">'</span>
                     <span class="s3">f'are lower than </span><span class="s2">{</span><span class="s1">valid_gap</span><span class="s2">} </span><span class="s3">for </span><span class="s2">{</span><span class="s1">feature</span><span class="s2">} </span><span class="s3">feature.</span><span class="s2">\U0001F913</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">indicator_to_invalid</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
</span><span class="s1">check_gaps(</span><span class="s3">'Delay_from_due_date'</span><span class="s2">,</span><span class="s4">31</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Annual Income 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Annual_Income.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Annual_Income'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Annual_Income'</span><span class="s1">)[</span><span class="s4">1</span><span class="s1">]</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Annual_Income'</span><span class="s2">,</span>
                  <span class="s1">show_features=[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s2">,</span><span class="s3">'Annual_Income'</span><span class="s1">]</span><span class="s2">,</span>
                  <span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">100</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">100000</span><span class="s1">).head(</span><span class="s4">3</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Annual income = hourly wage x weekly hours x weeks worked in a year. 
Let's take for example line 245, the Annual_Income value in June is ~5e+5, 
but in May and July the values are ~2e+4, Reminder it's an annual income, 
if the feature represents just the income from salary we can see that 
the Monthly_Inhand_Salary value does not change between January to August. 
Let's explore another scenario, Annual_Income - all Annual income: 
If during July the Customer sells a property, won the lottery, 
or inherited an amount of money, bonus, etc. 
-&gt;the amount will include in the august Annual_Income column because the feature represents income for a year. 
(but we don't know what was one year earlier :/) 
If the outliers values sit on August I can't prove that it's the wrong value if 
the Annual_Income includes all income(actually, we can solve this issue by looking at the test data, 
I can write a function with criteria that the indicator are Customer_ID&amp;Month indicator) 
 
</span><span class="s0">#%% 
</span><span class="s1">august_annual=get_indicators_df(</span><span class="s3">'Annual_Income'</span><span class="s2">,</span>
                                <span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">show_features=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">).loc[:</span><span class="s2">,</span>
              <span class="s1">[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Month'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s2">,</span><span class="s3">'Annual_Income'</span><span class="s1">]]\</span>
    <span class="s1">.query(</span><span class="s3">f&quot;Annual_Income&gt;</span><span class="s2">{</span><span class="s1">iqr_method(</span><span class="s3">'Annual_Income'</span><span class="s1">)[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)\</span>
    <span class="s1">.query(</span><span class="s3">&quot;Month == 'August'&quot;</span><span class="s1">)</span>

<span class="s1">august_annual.head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">I will cheat and check July month values in the test data. ;) 
</span><span class="s0">#%% 
</span><span class="s1">september_annual=test_df.query(</span><span class="s3">f&quot;Customer_ID.isin(</span><span class="s2">{</span><span class="s1">august_annual.Customer_ID.to_list()</span><span class="s2">}</span><span class="s3">) &quot;</span>
                               <span class="s3">f&quot;&amp; Month == 'September'&quot;</span><span class="s1">)[[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Annual_Income'</span><span class="s1">]].reset_index()</span>

<span class="s1">september_annual.head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">The table above shows that in September the annual income is lower than August Annual_Income and equal to July Annual_Income. 
</span><span class="s0">#%% md 
</span><span class="s1">Like the train data, test data also having mix type values in some numeric columns-&gt;convert using set_numeric_columns function. 
</span><span class="s0">#%% 
</span><span class="s1">set_numeric_columns(mix_type_num_col</span><span class="s2">,</span><span class="s1">df=test_df)</span>
<span class="s0">#%% 
</span><span class="s1">valid_values_dict={}</span>

<span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">range(august_annual.shape[</span><span class="s4">0</span><span class="s1">]):</span>

    <span class="s1">_=august_annual[[</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">]].iloc[i]\</span>
          <span class="s1">.to_numpy()/test_df[[</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">]]\</span>
    <span class="s1">[test_df.Customer_ID==august_annual.Customer_ID.iloc[i]].astype(</span><span class="s3">'float32'</span><span class="s1">).iloc[</span><span class="s4">0</span><span class="s1">].to_numpy()</span>

    <span class="s2">if </span><span class="s1">(~(_[</span><span class="s4">0</span><span class="s1">]&gt;</span><span class="s4">1.5</span><span class="s1">)) &amp; (~(</span><span class="s4">0.9</span><span class="s1">&lt;_[</span><span class="s4">1</span><span class="s1">]&lt;</span><span class="s4">1.1</span><span class="s1">)):</span>
        <span class="s1">valid_values_dict[august_annual.Customer_ID.iloc[i]]=\</span>
            <span class="s1">{</span><span class="s3">'August'</span><span class="s1">:august_annual[[</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">]].iloc[i]</span>
            <span class="s1">.to_numpy()</span><span class="s2">,</span><span class="s3">'September'</span><span class="s1">:test_df[[</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">]]</span>
            <span class="s1">[test_df.Customer_ID==august_annual.Customer_ID.iloc[i]].astype(</span><span class="s3">'float32'</span><span class="s1">).iloc[</span><span class="s4">0</span><span class="s1">].to_numpy() }</span>

        <span class="s1">print(</span><span class="s3">f'check customer id-&gt;</span><span class="s2">{</span><span class="s1">august_annual.Customer_ID.iloc[i]</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

<span class="s2">del </span><span class="s1">august_annual</span>
<span class="s0">#%% md 
</span><span class="s1">For Customer_ID CUS_0xa80 the gap between August to September is positive,I will explore deeper and check following September Month. 
</span><span class="s0">#%% 
</span><span class="s1">test_df[[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">]]\</span>
<span class="s1">[test_df.Customer_ID==list(valid_values_dict.keys())[</span><span class="s4">0</span><span class="s1">]]</span>
<span class="s0">#%% md 
</span><span class="s1">CUS_0xa80 Annual Income-&gt;illogic-&gt;will be replaced 
</span><span class="s0">#%% 
</span><span class="s1">insta</span><span class="s2">,</span><span class="s1">indi=get_indicators_df(</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s1">return_indicator= </span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">100000</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">indi.index(list(valid_values_dict.keys())[</span><span class="s4">0</span><span class="s1">])</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Annual_Income feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">_=indi.index(list(valid_values_dict.keys())[</span><span class="s4">0</span><span class="s1">])</span>
<span class="s1">indi.pop(_)</span>
<span class="s1">insta.pop(_)</span>
<span class="s1">replace_dict[</span><span class="s3">'Annual_Income'</span><span class="s1">]=([insta</span><span class="s2">,</span><span class="s1">indi]</span><span class="s2">,</span><span class="s3">'mode'</span><span class="s1">)</span>
<span class="s2">del </span><span class="s1">indi</span><span class="s2">,</span><span class="s1">insta</span><span class="s2">,</span><span class="s1">valid_values_dict</span>
<span class="s0">#%% md 
</span><span class="s1"># Num of Delayed Payment 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_of_Delayed_Payment.describe()</span>
<span class="s0">#%% 
</span><span class="s1">negative_duedate=get_indicators_df(</span><span class="s3">'Delay_from_due_date'</span><span class="s2">, </span><span class="s4">0</span><span class="s1">)[</span><span class="s4">1</span><span class="s1">]</span>
<span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span><span class="s1">show_features=</span><span class="s2">True,</span>
                  <span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).query(</span><span class="s3">f'Customer_ID.isin(</span><span class="s2">{</span><span class="s1">negative_duedate</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)\</span>
                    <span class="s1">[[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'Delay_from_due_date'</span><span class="s1">]].head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">negative_duedate</span>
<span class="s0">#%% md 
</span><span class="s1">*The average number of payments delayed by a person can't be negative number-&gt; I will replace the negative numbers.* 
</span><span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s1">positive=</span><span class="s2">False,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Num_of_Delayed_Payment feature represents the average number of payments delayed by a person-&gt; 
 Let's extract the exact num of delayed payments for outlier values, if getting negative number-&gt; 
 check if Delay_from_due_date feature also having negative number. 
</span><span class="s0">#%% md 
</span><span class="s1">*creating extract from mean function* 
 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">extract_from_mean(feature</span><span class="s2">,</span><span class="s1">indicators</span><span class="s2">,</span><span class="s1">df=train_df):</span>
    <span class="s1">df[</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]=</span><span class="s2">None</span>

    <span class="s2">for </span><span class="s1">id </span><span class="s2">in </span><span class="s1">tqdm(indicators):</span>
        <span class="s1">_=df[df[</span><span class="s3">'Customer_ID'</span><span class="s1">]==id]</span>
        <span class="s1">indexes=_.index.to_list()</span>

        <span class="s2">for </span><span class="s1">inst </span><span class="s2">in </span><span class="s1">indexes:</span>
            <span class="s1">mean_delayed=_[feature].loc[inst]</span>

            <span class="s2">if </span><span class="s1">inst==</span><span class="s4">0 </span><span class="s2">or </span><span class="s1">(inst-</span><span class="s4">7</span><span class="s1">)%</span><span class="s4">8</span><span class="s1">==</span><span class="s4">1</span><span class="s1">:</span>
                <span class="s1">df.loc[inst</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]=mean_delayed</span>
                <span class="s1">_.loc[inst</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]=mean_delayed</span>
                <span class="s2">pass</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">per_month=(mean_delayed*(_.loc[:inst].shape[</span><span class="s4">0</span><span class="s1">]))-\</span>
                          <span class="s1">(_.loc[:inst-</span><span class="s4">1</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]).sum()</span>
                <span class="s1">df.loc[inst</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]=per_month</span>
                <span class="s1">_.loc[inst</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s1">]=per_month</span>

    <span class="s2">return  </span><span class="s1">df</span>
<span class="s0">#%% 
</span><span class="s1">customers_2_drop=extract_from_mean(</span>
    <span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span>
    <span class="s1">df=get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">show_features=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">indicators=get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s1">)[</span><span class="s4">1</span><span class="s1">])\</span>
    <span class="s1">[[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Monthly_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'Delay_from_due_date'</span><span class="s1">]]\</span>
    <span class="s1">.query(</span><span class="s3">'Monthly_Delayed_Payment&lt;0'</span><span class="s1">).Customer_ID.unique()</span>
<span class="s0">#%% 
</span><span class="s1">customers=pd.Series(get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s1">)[</span><span class="s4">1</span><span class="s1">])</span>
<span class="s1">check_values_df=train_df[train_df.Customer_ID</span>
<span class="s1">.isin(customers[~customers.isin(customers_2_drop)])][[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s1">]]</span>

<span class="s2">del </span><span class="s1">customers</span><span class="s2">,</span><span class="s1">customers_2_drop</span>
<span class="s0">#%% 
</span><span class="s1">check_values_df.shape[</span><span class="s4">0</span><span class="s1">]/</span><span class="s4">8</span>
<span class="s0">#%% 
</span><span class="s1">check_values_df.head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s4">54</span>
                  <span class="s2">,</span><span class="s1">positive=</span><span class="s2">False,</span><span class="s1">return_df=</span><span class="s2">True, </span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">*Conclusion-&gt;Set threshold-&gt;[0,54]* 
</span><span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Num_of_Delayed_Payment feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'linked'</span>
                 <span class="s2">,</span><span class="s1">thresholds=[</span><span class="s4">0</span><span class="s2">,</span><span class="s4">54</span><span class="s1">]</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True,</span><span class="s1">std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Monthly Inhand Salary 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Monthly_Inhand_Salary.describe()</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Annual_Income feature to replace_dict dictionary.** 
 
</span><span class="s0">#%% 
</span><span class="s3">'''Replace only na'''</span>
<span class="s1">replace_dict_fun(</span><span class="s3">'Monthly_Inhand_Salary'</span><span class="s2">,</span><span class="s3">'mode'</span><span class="s2">,</span><span class="s1">only_na=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Num Credit Inquiries 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Num_Credit_Inquiries.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span>
                  <span class="s1">show_features=[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Age'</span><span class="s2">,</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span><span class="s3">'Month'</span><span class="s2">,</span>
                                 <span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s3">'Annual_Income'</span><span class="s2">,</span><span class="s3">'Credit_Score'</span><span class="s1">]</span>
                  <span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">Num_Credit_Inquiries feature having high values that are illogic, 
 to prove it let's take for example row 173 in the table above in June 
 the Num Credit Inquiries value is 1050, but in July the value is 6-&gt; 1050, 
  not logic because the value in June needs to be including in July. 
I will write a function that will check the value for the following months to outliers indicator. 
For the value in August, I need to know the value in September-&gt;will check the test data. 
</span><span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
# Not including Na.</span>
<span class="s1">ins=get_indicators_df(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">]</span>
<span class="s1">_=train_df.loc[ins</span><span class="s2">,</span><span class="s1">[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s1">]][train_df.loc[ins</span><span class="s2">,</span><span class="s3">'Month'</span><span class="s1">]==</span><span class="s3">'August'</span><span class="s1">]</span>
<span class="s0">#%% 
</span><span class="s1">customer_indicator=_.Customer_ID.to_list()</span>

<span class="s1">_[test_df.query(</span><span class="s3">f&quot;Month=='September' and Customer_ID.isin(</span><span class="s2">{</span><span class="s1">customer_indicator</span><span class="s2">}</span><span class="s3">)&quot;</span><span class="s1">)</span>
  <span class="s1">.Num_Credit_Inquiries.to_numpy()&gt;=_.Num_Credit_Inquiries.to_numpy()]</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">customer_indicator</span><span class="s2">,</span><span class="s1">ins</span>
<span class="s0">#%% 
</span><span class="s1">test_df.loc[:</span><span class="s2">,</span><span class="s1">[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Month'</span><span class="s2">,</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s1">]][test_df.Customer_ID==_.loc[</span><span class="s4">6751</span><span class="s2">,</span><span class="s1">:].Customer_ID]</span>
<span class="s0">#%% md 
</span><span class="s1">The table above shows that the value is illogic. 
This explored can do with other techniques per customer, e.g. mode, mean, and etc. 
</span><span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Annual_Income feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True,</span><span class="s1">std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Total EMI per month 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Total_EMI_per_month.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Total_EMI_per_month'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Total_EMI_per_month'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">describe_per_id(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span>
                <span class="s1">df=get_indicators_df(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">0</span><span class="s2">,</span><span class="s4">1000</span><span class="s1">]</span><span class="s2">,</span>
                                     <span class="s1">return_df=</span><span class="s2">True</span><span class="s1">)).query(</span><span class="s3">'std&gt;1000'</span><span class="s1">).head()</span>
<span class="s0">#%% 
</span><span class="s1">emi_df_check=get_indicators_df(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s1">[</span><span class="s4">2</span><span class="s2">,</span><span class="s4">2000</span><span class="s1">]</span>
                               <span class="s2">,</span><span class="s1">cus_std_threshold=</span><span class="s4">300</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">show_features=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s1">emi_df_check.head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">check_ime=check_gaps(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s4">1000</span><span class="s2">,</span><span class="s1">back_forward=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
</span><span class="s1">describe_per_id(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s1">df=train_df</span>
                <span class="s1">.query(</span><span class="s3">f'Customer_ID.isin(</span><span class="s2">{</span><span class="s1">list(check_ime)</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)</span><span class="s2">,</span><span class="s1">plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">describe_per_id(</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s1">df=train_df</span>
                <span class="s1">.query(</span><span class="s3">f'Customer_ID.isin(</span><span class="s2">{</span><span class="s1">list(check_ime.keys())</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">))[</span><span class="s3">'max'</span><span class="s1">].min()</span>
<span class="s0">#%% 
</span><span class="s1">train_df.query(</span><span class="s3">f'Customer_ID.isin(</span><span class="s2">{</span><span class="s1">list(check_ime)</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)\</span>
    <span class="s1">[[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s2">,</span><span class="s3">'Total_EMI_per_month'</span><span class="s2">,</span><span class="s3">'Num_Credit_Card'</span><span class="s2">,</span><span class="s3">'Num_Bank_Accounts'</span><span class="s1">]]\</span>
    <span class="s1">.query(</span><span class="s3">'Num_of_Loan==0 &amp; Num_Credit_Card==0'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">*EMI=Loan_amount*Interest_Rate*(1+Interest_Rate)*tenure_in_num_of_month/((1+Interest_Rate)*tenure_in_num_of_month-1) 
But it also can refer to a credit card payment transaction.-&gt;not changing the values.* 
</span><span class="s0">#%% 
# def change_ime(ime_to_check):</span>
<span class="s0">#</span>
<span class="s0">#     _1,_2=get_indicators_df('Total_EMI_per_month',thresholds=[0,1062],df=train_df.query(f'Customer_ID.isin({ime_to_check})'))</span>
<span class="s0">#     replace_dict['Total_EMI_per_month']=[[_1,_2],'linked']</span>
<span class="s0">#</span>
<span class="s0"># # check_ime(check_ime.keys())</span>
<span class="s0">#</span>
<span class="s0"># del check_ime</span>
<span class="s0">#%% md 
</span><span class="s1"># Outstanding Debt 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Outstanding_Debt.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Outstanding_Debt'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Outstanding_Debt'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Credit Utilization Ratio 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Credit_Utilization_Ratio.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Credit_Utilization_Ratio'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Amount invested monthly 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Amount_invested_monthly.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Amount_invested_monthly'</span><span class="s1">)</span>

<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Amount_invested_monthly'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Amount_invested_monthly'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">).head(</span><span class="s4">8</span><span class="s1">*</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Amount_invested_monthly'</span><span class="s2">,</span>
                  <span class="s1">show_features=[</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s3">'Amount_invested_monthly'</span><span class="s2">,</span><span class="s3">'Month'</span><span class="s1">]</span><span class="s2">,</span>
                  <span class="s1">thresholds=[</span><span class="s4">9999</span><span class="s2">,</span><span class="s4">10001</span><span class="s1">]</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">spectrum=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">I noticed that 10000.00000 it's a typing mistake, I saw that pattern in EMI end with .000000 
This pattern can find with regex. 
</span><span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Amount_invested_monthly'</span><span class="s2">,</span><span class="s1">thresholds=[</span><span class="s4">9999</span><span class="s2">,</span><span class="s4">10001</span><span class="s1">]</span>
                  <span class="s2">,</span><span class="s1">spectrum=</span><span class="s2">True,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">_=get_indicators_df(</span><span class="s3">'Amount_invested_monthly'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">return_na=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">)\</span>
    <span class="s1">.query(</span><span class="s3">'Amount_invested_monthly==10000| Amount_invested_monthly.isna()'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span>
<span class="s1">**Adding replace method and indicators for Amount_invested_monthly feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict[</span><span class="s3">'Amount_invested_monthly'</span><span class="s1">]=[[_.index.tolist()</span><span class="s2">,</span><span class="s1">_.Customer_ID.to_list()]</span><span class="s2">,</span><span class="s3">'mean'</span><span class="s1">]</span>
<span class="s0">#%% md 
</span><span class="s1"># Monthly Balance 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Monthly_Balance.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Monthly_Balance'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">iqr_method(</span><span class="s3">'Monthly_Balance'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Monthly_Balance'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Monthly_Balance'</span><span class="s2">,</span><span class="s4">0</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True,</span><span class="s1">cus_std_threshold=</span><span class="s4">0</span><span class="s1">).head(</span><span class="s4">2</span><span class="s1">*</span><span class="s4">8</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">train_df.query(</span><span class="s3">'Monthly_Balance&lt;0'</span><span class="s1">).Monthly_Balance.value_counts()</span>
<span class="s0">#%% md 
</span><span class="s1">The Value -3.333333e+26 it's a pattern mistake-&gt; I will replace the negative values. 
</span><span class="s0">#%% md 
</span>
<span class="s1">**Adding replace method and indicators for Monthly_Balance feature to replace_dict dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Monthly_Balance'</span><span class="s2">,</span><span class="s3">'mean'</span><span class="s2">,</span><span class="s1">thresholds=</span><span class="s4">0</span><span class="s2">,</span><span class="s1">return_na=</span><span class="s2">True,</span><span class="s1">std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Credit Mix 
</span><span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Credit_Mix'</span><span class="s2">,</span><span class="s1">multi_class=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Credit_Mix.isna().sum()</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Credit_Mix feature to replace_dict dictionary.** 
*Fill Na* 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Credit_Mix'</span><span class="s2">,</span><span class="s3">'mode'</span><span class="s2">,</span><span class="s1">only_na=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Changed Credit Limit 
 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Changed_Credit_Limit.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Changed_Credit_Limit'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Changed_Credit_Limit'</span><span class="s2">,</span><span class="s1">return_egg_plot=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Changed_Credit_Limit feature to replace_dict dictionary.** 
 
</span><span class="s0">#%% 
# Just Na indicator</span>
<span class="s1">replace_dict_fun(</span><span class="s3">'Changed_Credit_Limit'</span><span class="s2">,</span><span class="s3">'linked'</span><span class="s2">,</span><span class="s1">only_na=</span><span class="s2">True,</span><span class="s1">std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Credit History Age 
</span><span class="s0">#%% 
</span><span class="s1">train_df.Credit_History_Age.describe()</span>
<span class="s0">#%% 
</span><span class="s1">plots_by_categ(</span><span class="s3">'Credit_History_Age'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">get_indicators_df(</span><span class="s3">'Credit_History_Age'</span><span class="s2">,</span><span class="s1">return_df=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">*Filling Na in Credit_History_Age* 
</span><span class="s0">#%% 
</span><span class="s1">na_instances = train_df.index[train_df.Credit_History_Age.isnull()]</span>
<span class="s1">df_values = train_df.loc[:</span><span class="s2">, </span><span class="s1">[</span><span class="s3">'Credit_History_Age'</span><span class="s2">, </span><span class="s3">'Customer_ID'</span><span class="s1">]].drop(na_instances</span><span class="s2">, </span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>

<span class="s1">id = </span><span class="s2">None</span>
<span class="s1">min_index = </span><span class="s2">None</span>

<span class="s2">for </span><span class="s1">i </span><span class="s2">in </span><span class="s1">tqdm(na_instances):</span>
    <span class="s1">id = train_df.loc[i</span><span class="s2">, </span><span class="s3">'Customer_ID'</span><span class="s1">]</span>
    <span class="s1">min_index = \</span>
        <span class="s1">df_values[df_values.Customer_ID == id]\</span>
            <span class="s1">.sort_values(</span><span class="s3">'Credit_History_Age'</span><span class="s1">).index[</span><span class="s4">0</span><span class="s1">]</span>

    <span class="s1">train_df.loc[i</span><span class="s2">, </span><span class="s3">'Credit_History_Age'</span><span class="s1">] = (i - min_index) \</span>
                                            <span class="s1">+ df_values.loc[min_index</span><span class="s2">, </span><span class="s3">'Credit_History_Age'</span><span class="s1">]</span>

<span class="s2">del </span><span class="s1">na_instances</span><span class="s2">,</span><span class="s1">df_values</span><span class="s2">,</span><span class="s1">min_index</span><span class="s2">,</span><span class="s1">id</span>
<span class="s0">#%% md 
</span><span class="s1">*Checking the gaps after replace* 
</span><span class="s0">#%% 
</span><span class="s1">check_gaps(</span><span class="s3">'Credit_History_Age'</span><span class="s2">,</span><span class="s4">1</span><span class="s2">,</span><span class="s1">df=train_df)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding replace method and indicators for Payment_Behaviour feature to replace_dict dictionary.** 
 
</span><span class="s0">#%% 
</span><span class="s1">replace_dict_fun(</span><span class="s3">'Payment_Behaviour'</span><span class="s2">,</span><span class="s3">'mode'</span><span class="s2">,</span><span class="s1">only_na=</span><span class="s2">True,</span><span class="s1">std_threshold=</span><span class="s4">0</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Replace|fill class 
*Creating a class with Multi-Method  that will replace|fill values using.* 
</span><span class="s0">#%% 
</span><span class="s2">class </span><span class="s1">Fill_invalid_values:</span>
    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">df=</span><span class="s2">None, </span><span class="s1">feature_2_fill=</span><span class="s2">None, </span><span class="s1">indicator_feature=</span><span class="s2">None,</span>
                 <span class="s1">indicators=</span><span class="s2">None, </span><span class="s1">fill_insta=</span><span class="s2">None,</span><span class="s1">method=</span><span class="s2">None</span><span class="s1">):</span>
        <span class="s1">self.df = df</span>
        <span class="s1">self.feature_2_fill = feature_2_fill</span>
        <span class="s1">self.indicator_feature = indicator_feature</span>
        <span class="s1">self.indicators = indicators</span>
        <span class="s1">self.fill_insta = fill_insta</span>
        <span class="s1">self.method = method</span>


    <span class="s0"># '''The Lower_upper_lim method will reduce time complexity and check if backward fill is possible'''</span>
    <span class="s2">def </span><span class="s1">lower_upper_lim(self</span><span class="s2">, </span><span class="s1">inst):</span>
        <span class="s1">lower = inst - inst % </span><span class="s4">8</span>
        <span class="s1">upper = (inst + </span><span class="s4">7 </span><span class="s1">- inst % </span><span class="s4">8</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper</span>

    <span class="s2">def </span><span class="s1">customer_split(self</span><span class="s2">, </span><span class="s1">customer_id</span><span class="s2">, </span><span class="s1">low</span><span class="s2">, </span><span class="s1">upp):</span>
        <span class="s0"># Insert [self.df.loc[low:upp,self.indicator_feature]==customer_id] to double check.</span>
        <span class="s1">_ = self.df.drop(self.fill_insta).loc[low:upp</span><span class="s2">, </span><span class="s1">self.feature_2_fill][</span>
            <span class="s1">self.df.loc[low:upp</span><span class="s2">, </span><span class="s1">self.indicator_feature] == customer_id]</span>
        <span class="s2">return </span><span class="s1">_</span>

    <span class="s2">def </span><span class="s1">replace_invalid_values(self):</span>
        <span class="s1">n=</span><span class="s2">None</span>
        <span class="s2">for </span><span class="s1">indicator</span><span class="s2">, </span><span class="s1">instance </span><span class="s2">in </span><span class="s1">tqdm(zip(self.indicators</span><span class="s2">, </span><span class="s1">self.fill_insta)):</span>
            <span class="s1">lower</span><span class="s2">, </span><span class="s1">upper = self.lower_upper_lim(instance)</span>
            <span class="s1">customer_df = self.customer_split(indicator</span><span class="s2">, </span><span class="s1">lower</span><span class="s2">, </span><span class="s1">upper)</span>
            <span class="s2">if </span><span class="s1">customer_df.shape[</span><span class="s4">0</span><span class="s1">]&lt;=instance%</span><span class="s4">8</span><span class="s1">:</span>
                <span class="s1">n=-</span><span class="s4">1</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">n=instance%</span><span class="s4">8</span>
            <span class="s2">if </span><span class="s1">self.method == </span><span class="s3">'linked'</span><span class="s1">:</span>
                <span class="s1">self.df.loc[instance</span><span class="s2">, </span><span class="s1">self.feature_2_fill] = customer_df.iloc[n]</span>
            <span class="s2">elif </span><span class="s1">self.method == </span><span class="s3">'mode'</span><span class="s1">:</span>
                <span class="s1">self.df.loc[instance</span><span class="s2">, </span><span class="s1">self.feature_2_fill] = customer_df.mode().iloc[</span><span class="s4">0</span><span class="s1">]</span>
            <span class="s2">elif </span><span class="s1">self.method == </span><span class="s3">'mean'</span><span class="s1">:</span>
                <span class="s1">self.df.loc[instance</span><span class="s2">, </span><span class="s1">self.feature_2_fill] = customer_df.mean()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">return </span><span class="s1">print(</span><span class="s3">f'for </span><span class="s2">{</span><span class="s1">self.feature_2_fill</span><span class="s2">} </span><span class="s3">not set valid method'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">self.df</span>
<span class="s0">#%% md 
</span><span class="s1">**Replace\filling values** 
</span><span class="s0">#%% 
</span><span class="s2">for </span><span class="s1">feature </span><span class="s2">in </span><span class="s1">replace_dict.keys():</span>
    <span class="s1">fill=Fill_invalid_values(df=train_df</span><span class="s2">,</span><span class="s1">feature_2_fill=feature</span><span class="s2">,</span>
                             <span class="s1">indicator_feature=</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s1">indicators=replace_dict[feature][</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]</span><span class="s2">,</span><span class="s1">fill_insta=replace_dict[feature][</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">method=replace_dict[feature][</span><span class="s4">1</span><span class="s1">])</span>
    <span class="s1">fill.replace_invalid_values()</span>
<span class="s0">#%% md 
</span><span class="s1">**Check na values** 
</span><span class="s0">#%% 
</span><span class="s1">na_ratio_plot(train_df)</span>
<span class="s0">#%% 
</span><span class="s1">train_df.isna().sum().sum()==</span><span class="s4">0</span>
<span class="s0">#%% md 
</span><span class="s1">**Converting columns dtypes** 
</span><span class="s0">#%% 
</span><span class="s1">train_df.loc[:</span><span class="s2">,</span><span class="s3">'Auto Loan'</span><span class="s1">:].astype(np.int32)</span>
<span class="s1">convert_to_int=[</span><span class="s3">'Credit_History_Age'</span><span class="s2">,</span><span class="s3">'Num_Credit_Inquiries'</span><span class="s2">,</span>
                <span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s3">'Num_of_Loan'</span><span class="s1">]</span>
<span class="s1">train_df.loc[:</span><span class="s2">,</span><span class="s3">'Auto Loan'</span><span class="s1">:]=train_df.loc[:</span><span class="s2">,</span><span class="s3">'Auto Loan'</span><span class="s1">:].astype(np.int32)</span>
<span class="s1">train_df.loc[:</span><span class="s2">,</span><span class="s1">convert_to_int]=train_df.loc[:</span><span class="s2">,</span><span class="s1">convert_to_int].astype(np.int32)</span>
<span class="s2">del </span><span class="s1">convert_to_int</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
</span><span class="s1">train_df.head()</span>
<span class="s0">#%% 
# train_df.to_csv('done_train_df_b.csv',index=False)</span>
<span class="s0">#%% 
# train_df.to_csv('done_train_df.csv',index=False)</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
# train_df=pd.read_csv('done_train_df_b.csv')</span>
<span class="s0">#%% 
</span><span class="s1">features_order=pd.read_csv(</span><span class="s3">'done_train_df.csv'</span><span class="s1">).columns[</span><span class="s4">1</span><span class="s1">:]</span>
<span class="s0">#%% md 
</span><span class="s1">**Dropping irrelevant feature-&gt;Customer_ID** 
</span><span class="s0">#%% 
</span><span class="s1">train_df.drop(</span><span class="s3">'Customer_ID'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">train_df=train_df[features_order]</span>
<span class="s0">#%% md 
</span><span class="s1"># Visualization for credit score ratio for categorical features 
*Creating a function that returns visualization of the feature(target) attribute ratio per another feature attribute.* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">cat_score_ratio(df=</span><span class="s2">None,</span><span class="s1">feature=</span><span class="s2">None,</span><span class="s1">target=</span><span class="s2">None,</span>
                    <span class="s1">sort_by=</span><span class="s2">None,</span><span class="s1">show=</span><span class="s2">True,</span><span class="s1">per_feature_att=</span><span class="s2">True</span><span class="s1">):</span>

    <span class="s1">group_att_scores_ratio_df=df[[target</span><span class="s2">,</span><span class="s1">feature]].groupby(feature</span><span class="s2">,</span><span class="s1">group_keys=</span><span class="s2">False</span><span class="s1">)\</span>
        <span class="s1">.apply(</span><span class="s2">lambda </span><span class="s1">x: (x.value_counts()/x.value_counts().sum())*</span><span class="s4">100</span><span class="s1">)\</span>
        <span class="s1">.sort_values().rename(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">target</span><span class="s2">} </span><span class="s3">Ratio'</span><span class="s1">)</span>

    <span class="s1">att_scores_ratio_df=pd.DataFrame()</span>
    <span class="s1">fig=</span><span class="s2">None</span>
    <span class="s1">ax=</span><span class="s2">None</span>
    <span class="s2">for </span><span class="s1">n_att</span><span class="s2">,</span><span class="s1">att </span><span class="s2">in </span><span class="s1">enumerate(df[feature].unique()):</span>
        <span class="s2">if </span><span class="s1">n_att&gt;</span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">att_scores_ratio_df=pd.concat([att_scores_ratio_df</span><span class="s2">,</span><span class="s1">_3]</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">0</span><span class="s1">)</span>
        <span class="s1">_3=pd.DataFrame()</span>

        <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">score </span><span class="s2">in </span><span class="s1">enumerate(df[target].unique()):</span>
            <span class="s1">_4=(df.query(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">target</span><span class="s2">}</span><span class="s3">=='</span><span class="s2">{</span><span class="s1">score</span><span class="s2">}</span><span class="s3">'&quot;</span><span class="s1">).query(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">feature</span><span class="s2">}</span><span class="s3">=='</span><span class="s2">{</span><span class="s1">att</span><span class="s2">}</span><span class="s3">'&quot;</span><span class="s1">)</span>
            <span class="s1">.shape[</span><span class="s4">0</span><span class="s1">])/(df.query(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">feature</span><span class="s2">}</span><span class="s3">=='</span><span class="s2">{</span><span class="s1">att</span><span class="s2">}</span><span class="s3">'&quot;</span><span class="s1">).shape[</span><span class="s4">0</span><span class="s1">])*</span><span class="s4">100</span>
            <span class="s2">if </span><span class="s1">n_att==</span><span class="s4">0</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">i==</span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">att_scores_ratio_df[feature]=[att]</span>
                <span class="s1">att_scores_ratio_df[</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">score</span><span class="s2">}</span><span class="s3">'</span><span class="s1">]=[_4]</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s2">if </span><span class="s1">i==</span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">_3[feature]=[att]</span>
                <span class="s1">_3[</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">score</span><span class="s2">}</span><span class="s3">'</span><span class="s1">]=[_4]</span>
    <span class="s2">if </span><span class="s1">show:</span>

        <span class="s2">if </span><span class="s1">per_feature_att:</span>
            <span class="s1">att_scores_ratio_df.set_index(feature</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
            <span class="s1">n_rows=int(np.ceil( group_att_scores_ratio_df.index</span>
                                <span class="s1">.get_level_values(target).nunique()/</span><span class="s4">4</span><span class="s1">))</span>
            <span class="s1">n_columns=</span><span class="s4">4</span>
            <span class="s1">fig</span><span class="s2">,</span><span class="s1">ax=plt.subplots(nrows=n_rows</span><span class="s2">,</span><span class="s1">ncols=n_columns</span><span class="s2">,</span><span class="s1">figsize=[</span><span class="s4">20</span><span class="s2">,</span><span class="s4">6</span><span class="s1">]</span>
                                <span class="s2">,</span><span class="s1">gridspec_kw={</span><span class="s3">'wspace'</span><span class="s1">:</span><span class="s4">1.3</span><span class="s2">,</span><span class="s3">'hspace'</span><span class="s1">:</span><span class="s4">0.7</span><span class="s1">})</span>
            <span class="s1">plt.suptitle(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">feature</span><span class="s2">} {</span><span class="s1">target</span><span class="s2">}</span><span class="s3">s ratio (%)</span><span class="s2">\n</span><span class="s3">(Ascending order)'</span><span class="s2">,</span><span class="s1">fontsize=</span><span class="s4">15</span><span class="s2">,</span><span class="s1">y=</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">_2=</span><span class="s4">1</span>

            <span class="s2">for </span><span class="s1">n</span><span class="s2">,</span><span class="s1">att </span><span class="s2">in </span><span class="s1">enumerate( group_att_scores_ratio_df.index</span>
                                            <span class="s1">.get_level_values(target).unique()):</span>

                <span class="s1">k</span><span class="s2">,</span><span class="s1">j=divmod(_2</span><span class="s2">,</span><span class="s1">n_columns)</span>
                <span class="s1">_1= group_att_scores_ratio_df.loc[ group_att_scores_ratio_df</span>
                                                   <span class="s1">.index.get_level_values(target)==att]</span>

                <span class="s2">if  </span><span class="s1">group_att_scores_ratio_df.index.get_level_values(target).nunique()&lt;</span><span class="s4">5</span><span class="s1">:</span>
                    <span class="s1">_1.plot(kind=</span><span class="s3">'barh'</span><span class="s2">,</span><span class="s1">grid=</span><span class="s2">False,</span><span class="s1">ax=ax[j]</span><span class="s2">,</span><span class="s1">title=</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">att</span><span class="s2">} {</span><span class="s1">target</span><span class="s2">} </span><span class="s3">Ratio (%)'</span><span class="s2">,</span><span class="s1">rot=</span><span class="s4">45</span><span class="s1">)</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">_1.plot(kind=</span><span class="s3">'barh'</span><span class="s2">,</span><span class="s1">grid=</span><span class="s2">False,</span><span class="s1">ax=ax[k</span><span class="s2">,</span><span class="s1">j]</span><span class="s2">,</span><span class="s1">title=</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">att</span><span class="s2">} {</span><span class="s1">target</span><span class="s2">} </span><span class="s3">Ratio (%)'</span><span class="s2">,</span><span class="s1">rot=</span><span class="s4">45</span><span class="s1">)</span>
                <span class="s1">_2+=</span><span class="s4">1</span>

            <span class="s2">if  </span><span class="s1">group_att_scores_ratio_df.index.get_level_values(target).nunique()&lt;</span><span class="s4">5</span><span class="s1">:</span>
                <span class="s1">att_scores_ratio_df.sort_values(sort_by</span><span class="s2">,</span><span class="s1">ascending=</span><span class="s2">True</span><span class="s1">)\</span>
                    <span class="s1">.plot(kind=</span><span class="s3">'barh'</span><span class="s2">,</span><span class="s1">stacked=</span><span class="s2">True</span>
                          <span class="s2">,</span><span class="s1">title=</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">target</span><span class="s2">}</span><span class="s3">s ratio per </span><span class="s2">{</span><span class="s1">feature</span><span class="s2">}\n</span><span class="s3">(Ascending order by </span><span class="s2">{</span><span class="s1">sort_by</span><span class="s2">} {</span><span class="s1">target</span><span class="s2">}</span><span class="s3">)'</span>
                          <span class="s2">,</span><span class="s1">ax=ax[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">rot=</span><span class="s4">45</span><span class="s1">)</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">att_scores_ratio_df.sort_values(sort_by</span><span class="s2">,</span><span class="s1">ascending=</span><span class="s2">True</span><span class="s1">)\</span>
                    <span class="s1">.plot(kind=</span><span class="s3">'bar'</span><span class="s2">,</span><span class="s1">stacked=</span><span class="s2">True,</span><span class="s1">title=</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">target</span><span class="s2">}</span><span class="s3">s ratio (%) per'</span>
                                                        <span class="s3">f' </span><span class="s2">{</span><span class="s1">feature</span><span class="s2">}\n</span><span class="s3">(Ascending order by </span><span class="s2">{</span><span class="s1">sort_by</span><span class="s2">}</span><span class="s3">'</span>
                                                        <span class="s3">f' </span><span class="s2">{</span><span class="s1">target</span><span class="s2">}</span><span class="s3">)'</span><span class="s2">,</span><span class="s1">ax=ax[</span><span class="s4">0</span><span class="s2">,</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">rot=</span><span class="s4">45</span><span class="s1">)</span>
    <span class="s2">else</span><span class="s1">:</span>

        <span class="s2">return </span><span class="s1">att_scores_ratio_df</span>
<span class="s0">#%% 
</span><span class="s1">[cat_score_ratio(train_df</span><span class="s2">,</span><span class="s1">feature</span><span class="s2">,</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s3">'Good'</span><span class="s1">) </span><span class="s2">for </span><span class="s1">feature </span><span class="s2">in</span>
 <span class="s1">train_df.drop(</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">).select_dtypes(include=</span><span class="s3">'object'</span><span class="s1">).columns]</span>
<span class="s0">#%% md 
</span><span class="s1"># Features engineering | object features 
*Creating a function that converts a string to a number &amp; creates converting dictionary.* 
</span><span class="s0">#%% 
</span><span class="s1">obj_to_num_dict={}</span>
<span class="s1">num_to_obj_dict={}</span>
<span class="s2">def </span><span class="s1">convert_str_to_num(df=train_df):</span>
    <span class="s0"># df=pd.get_dummies(df,columns=['Occupation'])</span>
    <span class="s2">for </span><span class="s1">column </span><span class="s2">in </span><span class="s1">(df.select_dtypes(include=</span><span class="s3">'object'</span><span class="s1">).columns):</span>
        <span class="s1">obj_to_num_dict[column]={}</span>
        <span class="s1">num_to_obj_dict[column]={}</span>
        <span class="s2">for </span><span class="s1">n</span><span class="s2">,</span><span class="s1">i </span><span class="s2">in </span><span class="s1">enumerate(df[column].unique()):</span>
            <span class="s1">df[column]=df[column].replace(i</span><span class="s2">,</span><span class="s1">n+</span><span class="s4">1</span><span class="s1">)</span>
            <span class="s1">obj_to_num_dict[column][i]=n+</span><span class="s4">1</span>
            <span class="s1">num_to_obj_dict[column][n+</span><span class="s4">1</span><span class="s1">]=i</span>
        <span class="s1">df[column]=df[column].astype(</span><span class="s3">'uint8'</span><span class="s1">)</span>
    <span class="s2">return </span><span class="s1">df</span>

<span class="s0">#%% md 
</span><span class="s1">*Object type features encoding* 
</span><span class="s0">#%% 
</span><span class="s1">train_df=convert_str_to_num(df=train_df)</span>
<span class="s0">#%% 
</span><span class="s1">train_df.head()</span>
<span class="s0">#%% md 
</span><span class="s1"># correction between features. 
</span><span class="s0">#%% 
</span><span class="s1">correlation_plot(train_df)</span>
<span class="s0">#%% 
# from pandasgui import show</span>
<span class="s0"># show(train_df)</span>
<span class="s0">#%% 
</span><span class="s1">sns.pairplot(data=train_df[[</span><span class="s3">'Interest_Rate'</span><span class="s2">,</span><span class="s3">'Outstanding_Debt'</span><span class="s2">,</span><span class="s3">'Credit_Score'</span><span class="s1">]]</span>
             <span class="s1">.replace({</span><span class="s3">'Credit_Score'</span><span class="s1">:num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">]})</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Credit_Score'</span>
             <span class="s2">,</span><span class="s1">kind=</span><span class="s3">'kde'</span><span class="s2">,</span><span class="s1">height=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">aspect=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># pair plot 
</span><span class="s0">#%% 
</span><span class="s1">scatter_pair_plot=sns.pairplot(train_df.loc[:</span><span class="s2">,</span><span class="s1">:</span><span class="s3">'Credit_Score'</span><span class="s1">]</span>
                               <span class="s1">.replace({</span><span class="s3">'Credit_Score'</span><span class="s1">:num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">]})</span>
                               <span class="s2">,</span><span class="s1">height=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">aspect=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Credit_Score'</span><span class="s1">)</span>
<span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">scatter_pair_plot.axes.flat:</span>
    <span class="s1">ax.set_xlabel(ax.get_xlabel()</span><span class="s2">,</span><span class="s1">rotation=</span><span class="s4">90</span><span class="s2">,</span><span class="s1">loc=</span><span class="s3">'center'</span><span class="s1">)</span>
    <span class="s1">ax.set_ylabel(ax.get_ylabel()</span><span class="s2">,</span><span class="s1">rotation=</span><span class="s4">0</span><span class="s2">,</span><span class="s1">labelpad=</span><span class="s4">54</span><span class="s2">,</span><span class="s1">loc=</span><span class="s3">'center'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Kernal density estimate (KDE) pair plot 
</span><span class="s0">#%% 
</span><span class="s1">credit_scores_kde=sns.pairplot(train_df.loc[:</span><span class="s2">,</span><span class="s1">:</span><span class="s3">'Credit_Score'</span><span class="s1">]</span>
                               <span class="s1">.replace({</span><span class="s3">'Credit_Score'</span><span class="s1">:num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">]})</span>
                               <span class="s2">,</span><span class="s1">height=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">aspect=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">kind=</span><span class="s3">'kde'</span><span class="s1">)</span>
<span class="s2">for </span><span class="s1">ax </span><span class="s2">in </span><span class="s1">credit_scores_kde.axes.flat:</span>
    <span class="s1">ax.set_xlabel(ax.get_xlabel()</span><span class="s2">,</span><span class="s1">rotation=</span><span class="s4">90</span><span class="s2">,</span><span class="s1">loc=</span><span class="s3">'center'</span><span class="s1">)</span>
    <span class="s1">ax.set_ylabel(ax.get_ylabel()</span><span class="s2">,</span><span class="s1">rotation=</span><span class="s4">0</span><span class="s2">,</span><span class="s1">labelpad=</span><span class="s4">54</span><span class="s2">,</span><span class="s1">loc=</span><span class="s3">'center'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">sns.histplot(data=train_df.replace({</span><span class="s3">'Credit_Mix'</span><span class="s1">:num_to_obj_dict[</span><span class="s3">'Credit_Mix'</span><span class="s1">]})</span>
             <span class="s2">,</span><span class="s1">x=</span><span class="s3">'Interest_Rate'</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Credit_Mix'</span><span class="s2">,</span><span class="s1">kde=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Interest Rate Credit Mix correlation'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">sns.histplot(data=train_df.replace({</span><span class="s3">'Credit_Mix'</span><span class="s1">:num_to_obj_dict[</span><span class="s3">'Credit_Mix'</span><span class="s1">]})</span>
             <span class="s2">,</span><span class="s1">x=</span><span class="s3">'Num_of_Delayed_Payment'</span><span class="s2">,</span><span class="s1">hue=</span><span class="s3">'Credit_Mix'</span><span class="s2">,</span><span class="s1">kde=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">'Num_of_Delayed_Payment Credit Mix correlation'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Distribution per feature 
*Creating a function that plots each feature distribution(using Seaborn box|hist plot method).* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">dist_plots(df=train_df</span><span class="s2">,</span><span class="s1">plot_type=</span><span class="s3">'boxplot'</span><span class="s2">,</span><span class="s1">select_dtypes=</span><span class="s2">True,</span><span class="s1">columns=</span><span class="s4">6</span><span class="s1">):</span>
    <span class="s2">if </span><span class="s1">select_dtypes:</span>
        <span class="s1">df=df.select_dtypes(exclude=</span><span class="s3">'O'</span><span class="s1">)</span>
    <span class="s1">columns=columns</span>
    <span class="s1">rows=int(np.ceil(df.shape[</span><span class="s4">1</span><span class="s1">]/columns))</span>
    <span class="s0"># grid_kw=[{'wspace':0.3,'hspace':0.2} if plot_type!='boxplot' else None]</span>
    <span class="s1">fig</span><span class="s2">,</span><span class="s1">axes=plt.subplots(rows</span><span class="s2">,</span><span class="s1">columns</span><span class="s2">,</span><span class="s1">sharey=</span><span class="s3">'none'</span><span class="s2">,</span><span class="s1">figsize=[int(columns*</span><span class="s4">4</span><span class="s1">)</span><span class="s2">,</span><span class="s1">int(rows*</span><span class="s4">4</span><span class="s1">)]</span>
                          <span class="s2">,</span><span class="s1">gridspec_kw={</span><span class="s3">'wspace'</span><span class="s1">:</span><span class="s4">0.3</span><span class="s2">,</span><span class="s3">'hspace'</span><span class="s1">:</span><span class="s4">0.2</span><span class="s1">} </span><span class="s2">if </span><span class="s1">plot_type!=</span><span class="s3">'boxplot' </span><span class="s2">else None</span><span class="s1">)</span>
    <span class="s0"># fig,axes=plt.subplots(rows,columns,sharey='none',figsize=[columns*4,rows*4],</span>
    <span class="s0">#                       gridspec_kw={'wspace':0.3,'hspace':0.2})</span>

    <span class="s2">for </span><span class="s1">n</span><span class="s2">,</span><span class="s1">feature </span><span class="s2">in </span><span class="s1">enumerate(df):</span>
        <span class="s1">i</span><span class="s2">,</span><span class="s1">j=divmod(n</span><span class="s2">,</span><span class="s1">columns)</span>
        <span class="s2">if </span><span class="s1">plot_type==</span><span class="s3">'boxplot'</span><span class="s1">:</span>
            <span class="s1">sns.boxplot(x=df[feature]</span><span class="s2">,</span><span class="s1">ax=axes[i</span><span class="s2">,</span><span class="s1">j])</span>
        <span class="s2">elif </span><span class="s1">plot_type==</span><span class="s3">'hist'</span><span class="s1">:</span>
            <span class="s1">sns.histplot(x=df[feature]</span><span class="s2">,</span><span class="s1">ax=axes[i</span><span class="s2">,</span><span class="s1">j]</span><span class="s2">,</span><span class="s1">kde=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(train_df</span><span class="s2">,</span><span class="s1">plot_type=</span><span class="s3">'hist'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(train_df)</span>
<span class="s0">#%% md 
</span><span class="s1"># Target ratio 
</span><span class="s0">#%% 
</span><span class="s1">target_ratio(train_df)</span>
<span class="s0">#%% 
</span><span class="s1">train_df.Credit_Score.value_counts()</span>
<span class="s0">#%% md 
</span><span class="s1">**Imbalanced data.** 
</span><span class="s0">#%% md 
</span><span class="s1"># Skewness (imbalanced data) 
</span><span class="s0">#%% 
# list(map(lambda x:{x:(np.power(train_df[x]-train_df[x].mean(),3).sum())/((train_df[x].shape[0]-1)*np.power(train_df[x].std(),3))}, train_df))</span>
<span class="s1">train_df.skew().sort_values(ascending=</span><span class="s2">False</span><span class="s1">).plot(kind=</span><span class="s3">'barh'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">The outliers are valid and important 
Imbalanced data | outliers -&gt; skewed distribution. 
I will overcome that issue above by balancing the data with augmenting technics and changing the scale of the features-&gt;the technic will depend on the prediction algorithm. 
</span><span class="s0">#%% md 
</span><span class="s1"># Split&amp;Balance function 
*Creating a function to Preparing data for each prediction algorithm.* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">split_and_balance(df</span><span class="s2">,</span><span class="s1">target=</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">0</span><span class="s2">,</span>
                      <span class="s1">augmentation=RandomOverSampler(random_state=</span><span class="s4">16</span><span class="s1">)</span><span class="s2">,</span><span class="s1">remove_loan_type=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s2">if </span><span class="s1">remove_loan_type:</span>
        <span class="s1">df=df.loc[:</span><span class="s2">,</span><span class="s1">:</span><span class="s3">'Credit_Score'</span><span class="s1">]</span>
    <span class="s1">test=pd.DataFrame()</span>
    <span class="s1">nuniq_labels=df[target].nunique()</span>

    <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">l </span><span class="s2">in </span><span class="s1">enumerate(df[target].unique()):</span>
        <span class="s2">if </span><span class="s1">i ==</span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">test=df.query(</span><span class="s3">f'Credit_Score==</span><span class="s2">{</span><span class="s1">l</span><span class="s2">}</span><span class="s3">'</span><span class="s1">).sample(n=int((df.shape[</span><span class="s4">0</span><span class="s1">]*test_size)//nuniq_labels)</span>
                                                       <span class="s2">,</span><span class="s1">random_state=random_state)</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">test=pd.concat([test</span><span class="s2">,</span><span class="s1">df.query(</span><span class="s3">f'Credit_Score==</span><span class="s2">{</span><span class="s1">l</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
                           <span class="s1">.sample(n=int((df.shape[</span><span class="s4">0</span><span class="s1">]*test_size)//nuniq_labels)</span><span class="s2">,</span>
                                   <span class="s1">random_state=random_state)])</span>
    <span class="s1">train=df.drop(test.index)</span>

    <span class="s2">if </span><span class="s1">augmentation:</span>
        <span class="s1">xtrain</span><span class="s2">,</span><span class="s1">ytrain=augmentation.fit_resample(train.drop(target</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
                                                <span class="s1">train[target])</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">xtrain</span><span class="s2">,</span><span class="s1">ytrain=train.drop(target</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">train[target]</span>

    <span class="s1">xtest</span><span class="s2">,</span><span class="s1">ytest=test.drop(target</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">test[target]</span>

    <span class="s2">return </span><span class="s1">xtrain</span><span class="s2">,</span><span class="s1">xtest</span><span class="s2">,</span><span class="s1">ytrain</span><span class="s2">,</span><span class="s1">ytest</span>

<span class="s0">#%% 
</span><span class="s1">x</span><span class="s2">,</span><span class="s1">xx</span><span class="s2">,</span><span class="s1">y</span><span class="s2">,</span><span class="s1">yy=split_and_balance(df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">target_ratio(y</span><span class="s2">,</span><span class="s1">target=</span><span class="s2">None</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">target_ratio(yy</span><span class="s2">,</span><span class="s1">target=</span><span class="s2">None</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(x</span><span class="s2">,</span><span class="s1">plot_type=</span><span class="s3">'hist'</span><span class="s2">,</span><span class="s1">select_dtypes=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(x</span><span class="s2">,</span><span class="s1">select_dtypes=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Skewness (balanced train data) 
</span><span class="s0">#%% 
# list(map(lambda x:{x:(np.power(train_df[x]-train_df[x].mean(),3).sum())/((train_df[x].shape[0]-1)*np.power(train_df[x].std(),3))}, train_df))</span>
<span class="s1">x.skew().sort_values(ascending=</span><span class="s2">False</span><span class="s1">).plot(kind=</span><span class="s3">'barh'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">scal=PowerTransformer(standardize=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s1">x_scaled=scal.fit_transform(x)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(pd.DataFrame(x_scaled</span><span class="s2">,</span><span class="s1">columns=train_df.drop(</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">).columns)</span>
           <span class="s2">,</span><span class="s1">plot_type=</span><span class="s3">'hist'</span><span class="s2">,</span><span class="s1">select_dtypes=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">dist_plots(pd.DataFrame(x_scaled</span><span class="s2">,</span><span class="s1">columns=train_df.drop(</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">).columns)</span><span class="s2">,</span>
           <span class="s1">select_dtypes=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Skewness (scaled and balanced train data) 
</span><span class="s0">#%% 
</span><span class="s1">pd.DataFrame(x_scaled</span><span class="s2">,</span><span class="s1">columns=train_df.drop(</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>
             <span class="s1">.columns).skew().sort_values(ascending=</span><span class="s2">False</span><span class="s1">).plot(kind=</span><span class="s3">'barh'</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">x</span><span class="s2">,</span><span class="s1">xx</span><span class="s2">,</span><span class="s1">y</span><span class="s2">,</span><span class="s1">yy</span><span class="s2">,</span><span class="s1">x_scaled</span>
<span class="s0">#%% md 
</span><span class="s1">PowerTransformer(Sklearn) scaling to reduce the Skewed distribution, using the 'yeo-jonson' method because some features have negative values. 
</span><span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">scal</span>
<span class="s0">#%% md 
</span><span class="s1">**There is high frequency of outliers for some features -&gt; Tree-based algorithms are robust to outliers, 
also KNN with a high value of K (a low number of nearest neighbors will be susceptible to outliers). 
I will write a function to set the optimal K value.** 
</span><span class="s0">#%% md 
</span><span class="s1"># Stakeholder models 
*Stakeholder models using cross-validation-&gt;Imbalanced date-&gt; using StratifiedKFold.* 
**Hyp not tuned.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">stakeholder_model(features</span><span class="s2">,</span><span class="s1">targets</span><span class="s2">,</span><span class="s1">estimators</span><span class="s2">,</span><span class="s1">scaling_method=</span><span class="s2">None</span><span class="s1">):</span>
    <span class="s1">_=pd.DataFrame()</span>
    <span class="s0"># imbalance data</span>
    <span class="s1">k_fold=StratifiedKFold(</span><span class="s4">5</span><span class="s2">,</span><span class="s1">shuffle=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s2">for </span><span class="s1">model </span><span class="s2">in </span><span class="s1">tqdm(estimators):</span>
        <span class="s1">pipeline=make_pipeline(scaling_method</span><span class="s2">,</span><span class="s1">model)</span>
        <span class="s1">print(</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">model</span><span class="s2">} </span><span class="s3">cross val score|kfold-&gt;k-5:</span><span class="s2">\ 
        {</span><span class="s1">cross_val_score(pipeline</span><span class="s2">,</span><span class="s1">features</span><span class="s2">,</span><span class="s1">targets.replace({</span><span class="s4">1</span><span class="s1">:</span><span class="s4">0</span><span class="s2">,</span><span class="s4">2</span><span class="s1">:</span><span class="s4">1</span><span class="s2">,</span><span class="s4">3</span><span class="s1">:</span><span class="s4">2</span><span class="s1">})</span><span class="s2">,</span><span class="s1">cv=k_fold).mean()</span><span class="s2">}</span><span class="s3">&quot;</span><span class="s1">)</span>

<span class="s1">check_estimators=[XGBClassifier(n_jobs=-</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">RandomForestClassifier(n_jobs=-</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
                  <span class="s1">KNeighborsClassifier(n_jobs=-</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">AdaBoostClassifier()</span><span class="s2">,</span>
                  <span class="s1">HistGradientBoostingClassifier()</span><span class="s2">,</span><span class="s1">GradientBoostingClassifier()]</span>

<span class="s1">stakeholder_model(train_df.drop(</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">train_df.Credit_Score</span><span class="s2">,</span>
                  <span class="s1">check_estimators</span><span class="s2">,</span><span class="s1">PowerTransformer(method=</span><span class="s3">'yeo-johnson'</span><span class="s2">,</span><span class="s1">standardize=</span><span class="s2">True</span><span class="s1">))</span>
<span class="s0">#%% md 
</span><span class="s1"># Prediction function 
*Predict_model Function - return report, pipeline and each label scores (for weights to majority vote).* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">predict_model(estimator</span><span class="s2">,</span><span class="s1">df</span><span class="s2">,</span><span class="s1">target=</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span>
                  <span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">report=</span><span class="s2">True,</span><span class="s1">random_state=</span><span class="s4">0</span><span class="s2">,</span>
                  <span class="s1">imbalance=</span><span class="s2">None,</span><span class="s1">return_pipeline=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s1">x_train</span><span class="s2">,</span><span class="s1">x_test</span><span class="s2">,</span><span class="s1">y_train</span><span class="s2">,</span><span class="s1">y_test=split_and_balance(</span>
        <span class="s1">df</span><span class="s2">,</span><span class="s1">target</span><span class="s2">,</span><span class="s1">test_size</span><span class="s2">,</span><span class="s1">random_state=random_state</span><span class="s2">,</span><span class="s1">augmentation=imbalance)</span>


    <span class="s1">model_pipeline=make_pipeline(scaler</span><span class="s2">,</span><span class="s1">estimator)</span>
    <span class="s1">model_pipeline.fit(x_train</span><span class="s2">,</span><span class="s1">y_train)</span>

    <span class="s2">if </span><span class="s1">report:</span>
        <span class="s1">print(</span><span class="s3">f'test report:</span><span class="s2">\n{</span><span class="s1">classification_report(model_pipeline.predict(x_test)</span><span class="s2">,</span><span class="s1">y_test)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s1">print(</span><span class="s3">f'train report:</span><span class="s2">\n{</span><span class="s1">classification_report(model_pipeline.predict(x_train)</span><span class="s2">, </span><span class="s1">y_train)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">return_pipeline:</span>
        <span class="s1">report_test=pd.DataFrame.from_dict(classification_report(</span>
            <span class="s1">model_pipeline.predict(x_test)</span><span class="s2">,</span><span class="s1">y_test</span><span class="s2">,</span><span class="s1">output_dict=</span><span class="s2">True</span><span class="s1">))</span>

        <span class="s2">return </span><span class="s1">model_pipeline</span><span class="s2">,</span><span class="s1">report_test</span>
<span class="s0">#%% md 
</span><span class="s1"># Random forest algorithm 
**Optimal max depth to avoid over-fitting.** 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">scores_visual(df</span><span class="s2">,</span><span class="s1">target=</span><span class="s3">'Credit_Score'</span><span class="s2">,</span><span class="s1">estimator=</span><span class="s3">'RandomForestClassifier'</span><span class="s2">,</span>
                  <span class="s1">n_estimators=</span><span class="s4">600</span><span class="s2">,</span><span class="s1">k_fold=</span><span class="s4">5</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">0</span><span class="s2">,</span>
                  <span class="s1">max_depth=</span><span class="s4">35</span><span class="s2">,</span><span class="s1">criterion=</span><span class="s3">'entropy'</span><span class="s1">):</span>

    <span class="s0"># imbalance data</span>
    <span class="s1">kfold=StratifiedKFold(k_fold</span><span class="s2">,</span><span class="s1">shuffle=</span><span class="s2">True</span><span class="s1">)</span>
    <span class="s1">scores_df=pd.DataFrame(columns=[</span><span class="s3">'train'</span><span class="s2">,</span><span class="s3">'test'</span><span class="s2">,</span><span class="s3">'cross_val'</span><span class="s1">])</span>
    <span class="s1">X_train</span><span class="s2">,</span><span class="s1">X_test</span><span class="s2">,</span><span class="s1">Y_train</span><span class="s2">,</span><span class="s1">Y_test=split_and_balance(df</span><span class="s2">,</span><span class="s1">target</span><span class="s2">,</span><span class="s1">test_size</span><span class="s2">,</span>
                                                    <span class="s1">random_state=random_state</span><span class="s2">,</span><span class="s1">augmentation=</span><span class="s2">None</span><span class="s1">)</span>

    <span class="s2">for </span><span class="s1">depth </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">1</span><span class="s2">,</span><span class="s1">max_depth+</span><span class="s4">1</span><span class="s1">):</span>

        <span class="s1">model_r=RandomForestClassifier(n_estimators=n_estimators</span><span class="s2">,</span><span class="s1">n_jobs=-</span><span class="s4">1</span><span class="s2">,</span>
                                       <span class="s1">max_depth=depth</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">16</span><span class="s2">,</span><span class="s1">criterion=criterion)</span>
        <span class="s1">scores_df.loc[depth]={</span><span class="s3">'cross_val'</span><span class="s1">:cross_val_score(model_r</span><span class="s2">,</span><span class="s1">X_train</span><span class="s2">,</span><span class="s1">Y_train</span><span class="s2">,</span><span class="s1">cv=kfold)\</span>
            <span class="s1">.mean()</span><span class="s2">,</span><span class="s3">'train'</span><span class="s1">:model_r.fit(X_train</span><span class="s2">,</span><span class="s1">Y_train).score(X_train</span><span class="s2">,</span><span class="s1">Y_train)</span><span class="s2">,</span>
                              <span class="s3">'test'</span><span class="s1">:model_r.fit(X_train</span><span class="s2">,</span><span class="s1">Y_train).score(X_test</span><span class="s2">,</span><span class="s1">Y_test)}</span>

    <span class="s1">sns.scatterplot(scores_df)</span>
    <span class="s1">plt.title(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">estimator</span><span class="s2">} </span><span class="s3">(</span><span class="s2">{</span><span class="s1">n_estimators</span><span class="s2">} </span><span class="s3">estimators)-mean cross validation scores (Kfold=</span><span class="s2">{</span><span class="s1">kfold</span><span class="s2">}</span><span class="s3">)'</span><span class="s1">)</span>
    <span class="s1">sns.lineplot(scores_df)</span>
<span class="s0">#%% 
</span><span class="s1">scores_visual(train_df)</span>
<span class="s0">#%% 
</span><span class="s1">rforest_pipe</span><span class="s2">,</span><span class="s1">_=predict_model(estimator=RandomForestClassifier(max_depth=</span><span class="s4">22</span><span class="s2">,</span>
                                                              <span class="s1">n_estimators=</span><span class="s4">100</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">3</span><span class="s2">,</span>
                                                              <span class="s1">min_samples_split=</span><span class="s4">3</span><span class="s2">,</span><span class="s1">criterion=</span><span class="s3">'entropy'</span><span class="s2">,</span>
                                                              <span class="s1">bootstrap=</span><span class="s2">True,</span><span class="s1">n_jobs=-</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span><span class="s1">df=train_df</span><span class="s2">,</span>
                             <span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">24</span><span class="s1">)</span><span class="s2">,</span>
                             <span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Features importance 
</span><span class="s0">#%% 
</span><span class="s1">importance_df=pd.DataFrame([rforest_pipe[-</span><span class="s4">1</span><span class="s1">].feature_importances_</span><span class="s2">,</span>
                            <span class="s1">train_df.columns[:-</span><span class="s4">1</span><span class="s1">]]).T.sort_values(by=</span><span class="s4">0</span><span class="s2">,</span><span class="s1">ascending=</span><span class="s2">False</span><span class="s1">)</span>

<span class="s1">importance_df.columns=[</span><span class="s3">'Importance'</span><span class="s2">,</span><span class="s3">'Feature'</span><span class="s1">]</span>
<span class="s1">sns.catplot(data=importance_df</span><span class="s2">,</span><span class="s1">x=</span><span class="s3">'Importance'</span><span class="s2">,</span><span class="s1">y=</span><span class="s3">'Feature'</span><span class="s2">,</span><span class="s1">kind=</span><span class="s3">'bar'</span><span class="s2">, </span><span class="s1">height=</span><span class="s4">5</span><span class="s2">, </span><span class="s1">aspect=</span><span class="s4">2</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Create Pipelines dictionary.** 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores={}</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding trained Random Forest to the dictionary** 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'RandomForestClassifier'</span><span class="s1">]=predict_model(</span>
    <span class="s1">estimator=RandomForestClassifier(max_depth=</span><span class="s4">22</span><span class="s2">,</span><span class="s1">n_estimators=</span><span class="s4">100</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">3</span><span class="s2">,</span>
                                     <span class="s1">min_samples_split=</span><span class="s4">3</span><span class="s2">,</span><span class="s1">criterion=</span><span class="s3">'entropy'</span><span class="s2">,</span>
                                     <span class="s1">bootstrap=</span><span class="s2">True,</span><span class="s1">n_jobs=-</span><span class="s4">1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">24</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">rforest_pipe</span><span class="s2">,</span><span class="s1">importance_df</span>
<span class="s0">#%% md 
</span><span class="s1"># XGBoost algorithm 
</span><span class="s0">#%% 
</span><span class="s1">xgb_pipe</span><span class="s2">,</span><span class="s1">_=predict_model(estimator=XGBClassifier(reg_alpha=</span><span class="s4">9e-1</span><span class="s2">,</span><span class="s1">gamma=</span><span class="s4">3.4</span><span class="s2">,</span>
                                                 <span class="s1">n_estimators=</span><span class="s4">232</span><span class="s2">,</span><span class="s1">n_jobs=-</span><span class="s4">1</span><span class="s2">,</span><span class="s1">max_depth=</span><span class="s4">10</span><span class="s2">,</span>
                                                 <span class="s1">random_state=</span><span class="s4">14</span><span class="s2">,</span><span class="s1">learning_rate=</span><span class="s4">1e-1</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s1">df=train_df.replace({</span><span class="s3">'Credit_Score'</span><span class="s1">:{</span><span class="s4">1</span><span class="s1">:</span><span class="s4">0</span><span class="s2">,</span><span class="s4">2</span><span class="s1">:</span><span class="s4">1</span><span class="s2">,</span><span class="s4">3</span><span class="s1">:</span><span class="s4">2</span><span class="s1">}})</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span>
                         <span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">5</span><span class="s1">)</span><span class="s2">,</span>
                         <span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding trained XGBoost to the dictionary** 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'XGBoost'</span><span class="s1">]=predict_model(</span>
    <span class="s1">estimator=XGBClassifier(reg_alpha=</span><span class="s4">9e-1</span><span class="s2">,</span><span class="s1">gamma=</span><span class="s4">3.4</span><span class="s2">,</span><span class="s1">n_estimators=</span><span class="s4">232</span><span class="s2">,</span>
                            <span class="s1">n_jobs=-</span><span class="s4">1</span><span class="s2">,</span><span class="s1">max_depth=</span><span class="s4">10</span><span class="s2">,</span><span class="s1">random_state=</span><span class="s4">14</span><span class="s2">,</span>
                            <span class="s1">learning_rate=</span><span class="s4">1e-1</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">df=train_df.replace({</span><span class="s3">'Credit_Score'</span><span class="s1">:{</span><span class="s4">1</span><span class="s1">:</span><span class="s4">0</span><span class="s2">,</span><span class="s4">2</span><span class="s1">:</span><span class="s4">1</span><span class="s2">,</span><span class="s4">3</span><span class="s1">:</span><span class="s4">2</span><span class="s1">}})</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span>
    <span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">5</span><span class="s1">)</span><span class="s2">,</span><span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% 
</span><span class="s2">del </span><span class="s1">xgb_pipe</span>
<span class="s0">#%% md 
</span>
<span class="s1"># Histogram Boosting Gradient Classifier algorithm 
</span><span class="s0">#%% 
</span><span class="s1">predict_model(estimator=HistGradientBoostingClassifier(min_samples_leaf=</span><span class="s4">26</span><span class="s2">,</span><span class="s1">max_depth=</span><span class="s4">14</span><span class="s2">,</span>
                                                       <span class="s1">l2_regularization=</span><span class="s4">9e-1</span><span class="s2">,</span><span class="s1">max_iter=</span><span class="s4">1000</span><span class="s2">,</span>
                                                       <span class="s1">random_state=</span><span class="s4">7</span><span class="s2">,</span><span class="s1">loss=</span><span class="s3">'log_loss'</span><span class="s2">,</span>
                                                       <span class="s1">learning_rate=</span><span class="s4">1e-1</span><span class="s2">, </span><span class="s1">n_iter_no_change=</span><span class="s4">30</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">9</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">return_pipeline=</span><span class="s2">False,</span><span class="s1">report=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding trained HistGdb to the dictionary** 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'HistGdb'</span><span class="s1">]=predict_model(</span>
    <span class="s1">estimator=HistGradientBoostingClassifier(min_samples_leaf=</span><span class="s4">26</span><span class="s2">,</span><span class="s1">max_depth=</span><span class="s4">14</span><span class="s2">,</span>
                                             <span class="s1">l2_regularization=</span><span class="s4">9e-1</span><span class="s2">,</span><span class="s1">max_iter=</span><span class="s4">1000</span><span class="s2">,</span>
                                             <span class="s1">random_state=</span><span class="s4">7</span><span class="s2">,</span><span class="s1">loss=</span><span class="s3">'log_loss'</span><span class="s2">,</span>
                                             <span class="s1">learning_rate=</span><span class="s4">1e-1</span><span class="s2">, </span><span class="s1">n_iter_no_change=</span><span class="s4">30</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=</span><span class="s2">None,</span><span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">9</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># KNN algorithm 
*Elbow method function - tool to find the optimal number of K nearest neighbors.* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">k_elbow_method(df</span><span class="s2">,</span><span class="s1">test_size</span><span class="s2">,</span><span class="s1">balance_method</span><span class="s2">,</span><span class="s1">metrics</span><span class="s2">,</span><span class="s1">scaler</span><span class="s2">,</span>
                   <span class="s1">random_state=</span><span class="s4">0</span><span class="s2">,</span><span class="s1">min_k=</span><span class="s2">None,</span><span class="s1">max_k=</span><span class="s2">None,</span><span class="s1">plot=</span><span class="s2">True,</span>
                   <span class="s1">return_error_df=</span><span class="s2">False</span><span class="s1">):</span>

    <span class="s1">n=</span><span class="s4">0</span>
    <span class="s1">error_df=pd.DataFrame()</span>
    <span class="s1">error_list=[]</span>
    <span class="s1">k_list=[]</span>

    <span class="s2">if </span><span class="s1">min_k==</span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">_=int(np.sqrt(df.shape[</span><span class="s4">1</span><span class="s1">]-</span><span class="s4">1</span><span class="s1">))</span>
        <span class="s1">_=_-</span><span class="s4">2</span>
        <span class="s2">if </span><span class="s1">_%</span><span class="s4">2</span><span class="s1">==</span><span class="s4">0</span><span class="s1">:</span>
           <span class="s1">min_k=_-</span><span class="s4">1</span>
        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">min_k=_</span>
        <span class="s1">print(</span><span class="s3">f'min_k value set to </span><span class="s2">{</span><span class="s1">min_k</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">max_k==</span><span class="s2">None</span><span class="s1">:</span>
        <span class="s1">max_k=min_k+</span><span class="s4">12</span>
        <span class="s1">print(</span><span class="s3">f'min_k value set to </span><span class="s2">{</span><span class="s1">max_k</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">min_k&lt;=</span><span class="s4">0 </span><span class="s2">or </span><span class="s1">max_k&lt;=</span><span class="s4">0</span><span class="s1">:</span>
        <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">k </span><span class="s2">in </span><span class="s1">enumerate([min_k</span><span class="s2">,</span><span class="s1">max_k]):</span>
            <span class="s2">if </span><span class="s1">k&lt;=</span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">print(</span><span class="s3">f&quot;***</span><span class="s2">{</span><span class="s3">'Min_k' </span><span class="s2">if </span><span class="s1">i==</span><span class="s4">0 </span><span class="s2">else </span><span class="s3">'max_k'</span><span class="s2">} </span><span class="s3">value equel to </span><span class="s2">{</span><span class="s1">k</span><span class="s2">} </span><span class="s3">is not&quot;</span>
                      <span class="s3">f&quot; valid-&gt;</span><span class="s2">{</span><span class="s3">'Min_k' </span><span class="s2">if </span><span class="s1">i==</span><span class="s4">0 </span><span class="s2">else </span><span class="s3">'max_k'</span><span class="s2">} </span><span class="s3">value set to </span><span class="s2">{</span><span class="s4">1 </span><span class="s2">if </span><span class="s1">i==</span><span class="s4">0 </span><span class="s2">else </span><span class="s4">15</span><span class="s2">}</span><span class="s3">***&quot;</span><span class="s1">)</span>

                <span class="s2">if </span><span class="s1">i==</span><span class="s4">0</span><span class="s1">:</span>
                    <span class="s1">min_k=</span><span class="s4">1</span>
                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">max_k=</span><span class="s4">15</span>
    <span class="s2">if </span><span class="s1">min_k%</span><span class="s4">2</span><span class="s1">==</span><span class="s4">0</span><span class="s1">:</span>
        <span class="s1">min_k-=</span><span class="s4">1</span>

    <span class="s2">for </span><span class="s1">augment </span><span class="s2">in </span><span class="s1">balance_method:</span>
        <span class="s1">x_train</span><span class="s2">,</span><span class="s1">x_test</span><span class="s2">,</span><span class="s1">y_train</span><span class="s2">,</span><span class="s1">y_test=split_and_balance(df=df</span><span class="s2">,</span><span class="s1">test_size=test_size</span><span class="s2">,</span>
                                                        <span class="s1">random_state=random_state</span><span class="s2">,</span><span class="s1">augmentation=augment)</span>

        <span class="s2">for </span><span class="s1">scal </span><span class="s2">in </span><span class="s1">scaler:</span>
            <span class="s1">x_train=scal.fit_transform(x_train)</span>
            <span class="s1">x_test=scal.transform(x_test)</span>

            <span class="s2">for </span><span class="s1">metric </span><span class="s2">in </span><span class="s1">metrics:</span>
                <span class="s1">error_list=[]</span>
                <span class="s1">k_list=[]</span>

                <span class="s2">for </span><span class="s1">K </span><span class="s2">in </span><span class="s1">range(min_k</span><span class="s2">,</span><span class="s1">max_k+</span><span class="s4">1</span><span class="s2">,</span><span class="s4">2</span><span class="s1">):</span>
                    <span class="s1">knn=KNeighborsClassifier(n_neighbors=K</span><span class="s2">,</span><span class="s1">metric=metric)</span>
                    <span class="s1">knn.fit(x_train</span><span class="s2">,</span><span class="s1">y_train)</span>
                    <span class="s1">k_list.append(K)</span>
                    <span class="s1">error_list.append(np.mean(knn.predict(x_test)!=y_test))</span>
                    <span class="s2">if </span><span class="s1">K+</span><span class="s4">1</span><span class="s1">&gt;=max_k:</span>
                        <span class="s1">_2=</span><span class="s3">f&quot;</span><span class="s2">{</span><span class="s1">str(augment)</span><span class="s2">}\n</span><span class="s3">scaler:</span><span class="s2">{</span><span class="s1">str(scal)</span><span class="s2">}\n</span><span class="s3">metric:</span><span class="s2">{</span><span class="s1">metric</span><span class="s2">}</span><span class="s3">&quot;</span>
                        <span class="s1">_3=pd.DataFrame({(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">_2</span><span class="s2">}</span><span class="s3">'</span><span class="s2">,</span><span class="s3">'K_value'</span><span class="s1">):k_list</span><span class="s2">,</span><span class="s1">(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">_2</span><span class="s2">}</span><span class="s3">'</span><span class="s2">,</span><span class="s3">'Error_Ratio'</span><span class="s1">):error_list})</span>
                        <span class="s2">if </span><span class="s1">n==</span><span class="s4">0</span><span class="s1">:</span>
                            <span class="s1">error_df=_3</span>
                            <span class="s1">n+=</span><span class="s4">1</span>
                        <span class="s2">else</span><span class="s1">:</span>
                            <span class="s1">error_df=pd.concat([error_df</span><span class="s2">,</span><span class="s1">_3]</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)</span>

    <span class="s2">if </span><span class="s1">plot:</span>
        <span class="s1">params=error_df.columns</span>
        <span class="s1">n_iter=error_df.shape[</span><span class="s4">1</span><span class="s1">]//</span><span class="s4">2</span>
        <span class="s1">rows=</span><span class="s4">1</span>
        <span class="s1">columns=n_iter</span>

        <span class="s2">if </span><span class="s1">n_iter&gt;</span><span class="s4">3</span><span class="s1">:</span>
            <span class="s1">rows=int(np.ceil(n_iter/</span><span class="s4">3</span><span class="s1">))</span>
            <span class="s1">columns=</span><span class="s4">3</span>

        <span class="s2">if </span><span class="s1">n_iter==</span><span class="s4">1</span><span class="s1">:</span>
            <span class="s1">sns.lineplot(x=error_df[params[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]</span><span class="s2">,</span>
                         <span class="s1">y=error_df[params[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]).set(title=params[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">0</span><span class="s1">])</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">fig</span><span class="s2">,</span><span class="s1">axes=plt.subplots(nrows=rows</span><span class="s2">,</span><span class="s1">ncols=columns</span><span class="s2">,</span><span class="s1">sharey=</span><span class="s3">'all'</span><span class="s2">,</span>
                                  <span class="s1">figsize=[columns*</span><span class="s4">4</span><span class="s2">,</span><span class="s1">rows*</span><span class="s4">6</span><span class="s1">]</span><span class="s2">,</span>
                                  <span class="s1">gridspec_kw={</span><span class="s3">'wspace'</span><span class="s1">:</span><span class="s4">0.45</span><span class="s2">,</span><span class="s3">'hspace'</span><span class="s1">:</span><span class="s4">0.3</span><span class="s1">})</span>

            <span class="s1">fig.suptitle(</span><span class="s3">'Elbow_method(K value,Error_Rate)'</span><span class="s2">,</span><span class="s1">fontsize=</span><span class="s4">18</span><span class="s2">,</span><span class="s1">y=</span><span class="s4">1</span><span class="s1">)</span>

            <span class="s1">_=</span><span class="s4">0</span>

            <span class="s2">for </span><span class="s1">iter </span><span class="s2">in </span><span class="s1">range(</span><span class="s4">0</span><span class="s2">,</span><span class="s1">n_iter*</span><span class="s4">2</span><span class="s2">,</span><span class="s4">2</span><span class="s1">):</span>
                <span class="s1">i</span><span class="s2">,</span><span class="s1">j=divmod(_</span><span class="s2">,</span><span class="s1">columns)</span>

                <span class="s2">if </span><span class="s1">rows==</span><span class="s4">1</span><span class="s1">:</span>
                    <span class="s1">sns.lineplot(x=error_df[params[</span><span class="s4">0</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]</span><span class="s2">,</span>
                                 <span class="s1">y=error_df[params[</span><span class="s4">1</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]</span><span class="s2">,</span>
                                 <span class="s1">ax=axes[j]).set(title=params[</span><span class="s4">0</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">])</span>

                <span class="s2">else</span><span class="s1">:</span>
                    <span class="s1">sns.lineplot(x=error_df[params[</span><span class="s4">0</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">0</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]</span><span class="s2">,</span>
                                 <span class="s1">y=error_df[params[</span><span class="s4">1</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">]][params[</span><span class="s4">1</span><span class="s1">][</span><span class="s4">1</span><span class="s1">]]</span><span class="s2">,</span>
                                 <span class="s1">ax=axes[i</span><span class="s2">,</span><span class="s1">j]).set(title=params[</span><span class="s4">0</span><span class="s1">+iter][</span><span class="s4">0</span><span class="s1">])</span>

                <span class="s1">_+=</span><span class="s4">1</span>

    <span class="s2">if </span><span class="s1">return_error_df:</span>
        <span class="s2">return </span><span class="s1">error_df</span>
<span class="s0">#%% 
</span><span class="s1">error_df=k_elbow_method(train_df</span><span class="s2">,</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">balance_method=[ADASYN()</span><span class="s2">,</span>
                                                     <span class="s1">RandomOverSampler(random_state=</span><span class="s4">11</span><span class="s1">)]</span><span class="s2">,</span>
                        <span class="s1">metrics=[</span><span class="s3">'l1'</span><span class="s2">,</span><span class="s3">'l2'</span><span class="s1">]</span><span class="s2">,</span><span class="s1">scaler=[PowerTransformer()]</span><span class="s2">,</span><span class="s1">min_k=</span><span class="s4">3</span><span class="s2">,</span><span class="s1">max_k=</span><span class="s4">15</span><span class="s2">,</span>
                        <span class="s1">plot=</span><span class="s2">True,</span><span class="s1">return_error_df=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s1">error_df.min().min()</span>
<span class="s0">#%% 
</span><span class="s1">predict_model(estimator=KNeighborsClassifier(n_neighbors=</span><span class="s4">5</span><span class="s2">,</span><span class="s1">metric=</span><span class="s3">'l1'</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=PowerTransformer()</span><span class="s2">,</span>
              <span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">11</span><span class="s1">)</span><span class="s2">,</span>
              <span class="s1">return_pipeline=</span><span class="s2">False,</span><span class="s1">report=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding trained Knn to the dictionary** 
 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'Knn'</span><span class="s1">]=predict_model(</span>
    <span class="s1">estimator=KNeighborsClassifier(n_neighbors=</span><span class="s4">5</span><span class="s2">,</span><span class="s1">metric=</span><span class="s3">'l1'</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">df=train_df</span><span class="s2">,</span><span class="s1">test_size=</span><span class="s4">0.2</span><span class="s2">,</span><span class="s1">scaler=PowerTransformer()</span><span class="s2">,</span>
    <span class="s1">imbalance=RandomOverSampler(random_state=</span><span class="s4">11</span><span class="s1">)</span><span class="s2">,</span>
    <span class="s1">return_pipeline=</span><span class="s2">True,</span><span class="s1">report=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span>


<span class="s1"># FC neural network 
*Creating a script to tune NN Hyp (trained outside this notebook).* 
 
</span><span class="s0">#%% 
# x_train, x_test, y_train, y_test = split_and_balance(train_df, test_size=0.2,</span>
<span class="s0">#                                                      augmentation=RandomOverSampler(random_state=17))</span>
<span class="s0">#</span>
<span class="s0"># scaler = PowerTransformer()</span>
<span class="s0"># x_train = scaler.fit_transform(x_train)</span>
<span class="s0"># x_test = scaler.transform(x_test)</span>
<span class="s0">#</span>
<span class="s0">#</span>
<span class="s0"># class Fc(nn.Module):</span>
<span class="s0">#     def __init__(self, input_size, output_size,</span>
<span class="s0">#                  n_layers, hidden_sizes,</span>
<span class="s0">#                  l_activations, l_dropouts):</span>
<span class="s0">#         super().__init__()</span>
<span class="s0">#         layers = []</span>
<span class="s0">#         for _, size, activ, drop in zip(range(n_layers), hidden_sizes,</span>
<span class="s0">#                                         l_activations, l_dropouts):</span>
<span class="s0">#             if _ == 0:</span>
<span class="s0">#                 layers.append(nn.Linear(input_size, size))</span>
<span class="s0">#                 layers.append(nn.Dropout(drop))</span>
<span class="s0">#                 layers.append(getattr(nn, activ)())</span>
<span class="s0">#             else:</span>
<span class="s0">#                 layers.append(nn.Linear(hidden_sizes[_ - 1], size))</span>
<span class="s0">#                 layers.append(nn.Dropout(drop))</span>
<span class="s0">#                 layers.append(getattr(nn, activ)())</span>
<span class="s0">#         layers.append(nn.Linear(hidden_sizes[-1], output_size))</span>
<span class="s0">#</span>
<span class="s0">#         self.fcnn_model = nn.Sequential(*layers)</span>
<span class="s0">#</span>
<span class="s0">#     def forward(self, x):</span>
<span class="s0">#         return self.fcnn_model(x)</span>
<span class="s0">#</span>
<span class="s0">#</span>
<span class="s0"># class Data(Dataset):</span>
<span class="s0">#     def __init__(self):</span>
<span class="s0">#         self.x = torch.tensor(x_train, dtype=torch.float32)</span>
<span class="s0">#         self.y = torch.tensor(y_train, dtype=torch.float32).view(-1)</span>
<span class="s0">#         self.instances = self.x.shape[0]</span>
<span class="s0">#</span>
<span class="s0">#     def __len__(self):</span>
<span class="s0">#         return self.instances</span>
<span class="s0">#</span>
<span class="s0">#     def __getitem__(self, item):</span>
<span class="s0">#         return self.x[item], self.y[item]</span>
<span class="s0">#</span>
<span class="s0">#</span>
<span class="s0"># def objective(trial):</span>
<span class="s0">#     n_layers = trial.suggest_int('nlayers', 2, 3, 1)</span>
<span class="s0">#     hidden_sizes = []</span>
<span class="s0">#     l_activations = ['LeakyReLU','LeakyReLU']</span>
<span class="s0">#     #Sets drop-out values to avoid over-fitting.</span>
<span class="s0">#     l_dropouts = [0.3, 0.2]</span>
<span class="s0">#     if n_layers != 2:</span>
<span class="s0">#         l_dropouts.append(0.2)</span>
<span class="s0">#         l_activations.append('LeakyReLU')</span>
<span class="s0">#     for l in range(n_layers):</span>
<span class="s0">#         hidden_sizes.append(trial.suggest_int(f'size_l{l}', 32 * 6, 128 * 10, 32))</span>
<span class="s0">#     # Sets activations function to break linearity to &quot;leaky relu&quot; because data having negative values.</span>
<span class="s0">#         # l_activations.append(trial.suggest_categorical(f'activation_l{l}', ['LeakyReLU','Sigmoid','ReLU']))</span>
<span class="s0">#     # sets learning rate as 1e-3</span>
<span class="s0">#     # learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e-1,step=1e-7)</span>
<span class="s0">#     model = Fc(input_size=x_train.shape[1], output_size=1, n_layers=n_layers,</span>
<span class="s0">#                hidden_sizes=hidden_sizes, l_activations=l_activations,</span>
<span class="s0">#                l_dropouts=l_dropouts).to(device=device)</span>
<span class="s0">#</span>
<span class="s0">#     criterion = nn.MSELoss()</span>
<span class="s0">#     # Sets weight_decay (L2 penalty) to avoid over-fitting while training.</span>
<span class="s0">#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-3)</span>
<span class="s0">#     df = Data()</span>
<span class="s0">#     epochs = 30</span>
<span class="s0">#     train_loader = DataLoader(dataset=df, batch_size=x_train.shape[0] // 6, shuffle=True)</span>
<span class="s0">#     loss = None</span>
<span class="s0">#     for epoch in range(epochs):</span>
<span class="s0">#         for batch, (features, labels) in enumerate(train_loader):</span>
<span class="s0">#             # Adding data to cuda</span>
<span class="s0">#             features = features.to(device=device)</span>
<span class="s0">#             labels = labels.to(device=device)</span>
<span class="s0">#             predictions = model.forward(features).view(-1).to(device=device)</span>
<span class="s0">#             loss = torch.sqrt(criterion(predictions, labels).to(device=device))</span>
<span class="s0">#             print(f&quot;batch:{batch}\nepoch:{epoch} loss: {loss.to(device='cpu')}&quot;)</span>
<span class="s0">#             # Backprop</span>
<span class="s0">#             loss.backward()</span>
<span class="s0">#             # Optimizer step</span>
<span class="s0">#             optimizer.step()</span>
<span class="s0">#             # Reset gradient</span>
<span class="s0">#             optimizer.zero_grad(set_to_none=True)</span>
<span class="s0">#     # For the lowest loss function value, the model state dictionary will preserve.</span>
<span class="s0">#     if loss_check[-1] &gt; loss:</span>
<span class="s0">#         for param, param_val in zip(['n_layers', 'hidden_sizes', 'l_activations', 'l_dropouts'],</span>
<span class="s0">#                                     [n_layers, hidden_sizes, l_activations, l_dropouts]):</span>
<span class="s0">#             best_trial_params[param] = param_val</span>
<span class="s0">#         torch.save(model.state_dict(), 'best_trial_st_dict.pth')</span>
<span class="s0">#         print(f'old loss:{loss_check[-1]}\nnew loss: {loss}')</span>
<span class="s0">#         loss_check.append(loss)</span>
<span class="s0">#     return loss</span>
<span class="s0">#</span>
<span class="s0">#</span>
<span class="s0"># def detailed_objective(trial):</span>
<span class="s0">#     n_layers = trial.suggest_int('nlayers', 2, 3, 1)</span>
<span class="s0">#     hidden_sizes = []</span>
<span class="s0">#     # Set activations</span>
<span class="s0">#     l_activations = ['LeakyReLU', 'LeakyReLU']</span>
<span class="s0">#     #Sets drop-out values to avoid over-fitting.</span>
<span class="s0">#     l_dropouts = [0.3, 0.2]</span>
<span class="s0">#     if n_layers != 2:</span>
<span class="s0">#         l_dropouts.append(0.2)</span>
<span class="s0">#         l_activations.append('LeakyReLU')</span>
<span class="s0">#</span>
<span class="s0">#     for l in range(n_layers):</span>
<span class="s0">#         hidden_sizes.append(trial.suggest_int(f'size_l{l}', 32 * 5, 128 * 10, 32))</span>
<span class="s0">#         l_activations.append(trial.suggest_categorical(f'activation_l{l}', ['LeakyReLU', 'ReLU']))</span>
<span class="s0">#     # sets learning rate as 1e-4</span>
<span class="s0">#     # learning_rate = trial.suggest_float('learning_rate', 1e-7, 1e-1,step=1e-7)</span>
<span class="s0">#     model = Fc(input_size=x_train.shape[1], output_size=1, n_layers=n_layers,</span>
<span class="s0">#                hidden_sizes=hidden_sizes,l_activations=l_activations,</span>
<span class="s0">#                l_dropouts=l_dropouts).to(device=device)</span>
<span class="s0">#</span>
<span class="s0">#     model.load_state_dict(torch.load('best_trial_st_dict.pth'))</span>
<span class="s0">#     criterion = nn.MSELoss()</span>
<span class="s0">#     # Sets weight_decay (L2 penalty) to avoid over-fitting.</span>
<span class="s0">#     optimizer = torch.optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-3)</span>
<span class="s0">#     df = Data()</span>
<span class="s0">#     epochs = 5000</span>
<span class="s0">#     train_loader = DataLoader(dataset=df, batch_size=x_train.shape[0] // 6, shuffle=True)</span>
<span class="s0">#     loss = None</span>
<span class="s0">#     for epoch in range(epochs):</span>
<span class="s0">#         for batch, (features, labels) in enumerate(train_loader):</span>
<span class="s0">#             # Adding data to cuda</span>
<span class="s0">#             features = features.to(device=device)</span>
<span class="s0">#             labels = labels.to(device=device)</span>
<span class="s0">#             predictions = model.forward(features).view(-1).to(device=device)</span>
<span class="s0">#             loss = torch.sqrt(criterion(predictions, labels).to(device=device))</span>
<span class="s0">#             # For the lowest loss function value, the model state dictionary will preserve.</span>
<span class="s0">#             if loss_check[-1] &gt; loss:</span>
<span class="s0">#                 for param, param_val in zip(['n_layers', 'hidden_sizes', 'l_activations', 'l_dropouts'],</span>
<span class="s0">#                                             [n_layers, hidden_sizes, l_activations, l_dropouts]):</span>
<span class="s0">#                     best_trial_params[param] = param_val</span>
<span class="s0">#                 torch.save(model.state_dict(), 'best_trial_st_dict.pth')</span>
<span class="s0">#</span>
<span class="s0">#                 print(f'old loss:{loss_check[-1]}\nnew loss: {loss}')</span>
<span class="s0">#                 loss_check.append(loss)</span>
<span class="s0">#             acc_train = (model(torch.tensor(x_train, dtype=torch.float32).to(device=device))</span>
<span class="s0">#                          .round().to(device='cpu').view(-1) == torch.tensor(y_train.to_numpy()))\</span>
<span class="s0">#                             .sum() / y_train.shape[0]</span>
<span class="s0">#</span>
<span class="s0">#             acc_test = (model(torch.tensor(x_test, dtype=torch.float32).to(device=device)).round().to(</span>
<span class="s0">#                 device='cpu').view(-1) == torch.tensor(y_test.to_numpy())).sum() / y_test.shape[0]</span>
<span class="s0">#             print(</span>
<span class="s0">#                 f&quot;batch:{batch}\nepoch:{epoch}\nloss: {loss.to(device='cpu')}\n&quot;</span>
<span class="s0">#                 f&quot;accuracy: train: {acc_train}, test:{acc_test}&quot;)</span>
<span class="s0">#             # Backprop</span>
<span class="s0">#             loss.backward()</span>
<span class="s0">#             # Optimizer step</span>
<span class="s0">#             optimizer.step()</span>
<span class="s0">#             # Reset gradient</span>
<span class="s0">#             optimizer.zero_grad(set_to_none=True)</span>
<span class="s0">#</span>
<span class="s0">#     return model</span>
<span class="s0">#</span>
<span class="s0">#</span>
<span class="s0"># if __name__ == '__main__':</span>
<span class="s0">#     loss_check = [1]</span>
<span class="s0">#     best_trial_params = {}</span>
<span class="s0">#     study = optuna.create_study(direction='minimize')</span>
<span class="s0">#     study.optimize(objective, n_trials=100)</span>
<span class="s0">#     print(f'best value:{study.best_value} (params: {study.best_params})')</span>
<span class="s0">#     with open('study_best_trail.txt', 'w') as f:</span>
<span class="s0">#         f.write('dict = ' + repr(study.best_params) + '\n')</span>
<span class="s0">#     best_params = study.best_params</span>
<span class="s0">#     # Training the best trial.</span>
<span class="s0">#     best_trial_model = detailed_objective(study.best_trial)</span>
<span class="s0">#%% 
</span><span class="s1">device = torch.device(</span><span class="s3">'cuda' </span><span class="s2">if </span><span class="s1">torch.cuda.is_available() </span><span class="s2">else </span><span class="s3">'cpu'</span><span class="s1">)</span>
<span class="s2">class </span><span class="s1">Fc_nn(nn.Module):</span>

    <span class="s2">def </span><span class="s1">__init__(self</span><span class="s2">, </span><span class="s1">input_size</span><span class="s2">, </span><span class="s1">output_size</span><span class="s2">, </span><span class="s1">n_layers</span><span class="s2">,</span>
                 <span class="s1">hidden_sizes</span><span class="s2">, </span><span class="s1">l_activations</span><span class="s2">, </span><span class="s1">l_dropouts):</span>

        <span class="s1">super().__init__()</span>
        <span class="s1">layers = []</span>
        <span class="s0"># for _ in range(n_layers):</span>
        <span class="s2">for </span><span class="s1">_</span><span class="s2">, </span><span class="s1">size</span><span class="s2">, </span><span class="s1">activ</span><span class="s2">, </span><span class="s1">drop </span><span class="s2">in </span><span class="s1">zip(range(n_layers)</span><span class="s2">, </span><span class="s1">hidden_sizes</span><span class="s2">,</span>
                                        <span class="s1">l_activations</span><span class="s2">, </span><span class="s1">l_dropouts):</span>

            <span class="s2">if </span><span class="s1">_ == </span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">layers.append(nn.Linear(input_size</span><span class="s2">, </span><span class="s1">size))</span>
                <span class="s1">layers.append(nn.Dropout(drop))</span>
                <span class="s1">layers.append(getattr(nn</span><span class="s2">, </span><span class="s1">activ)())</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">layers.append(nn.Linear(hidden_sizes[_ - </span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">size))</span>
                <span class="s1">layers.append(nn.Dropout(drop))</span>
                <span class="s1">layers.append(getattr(nn</span><span class="s2">, </span><span class="s1">activ)())</span>
        <span class="s1">layers.append(nn.Linear(hidden_sizes[-</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">output_size))</span>

        <span class="s1">self.fcnn_model = nn.Sequential(*layers)</span>

    <span class="s2">def </span><span class="s1">forward(self</span><span class="s2">, </span><span class="s1">x):</span>
        <span class="s2">return </span><span class="s1">self.fcnn_model(x)</span>


<span class="s1">l_activations = [</span><span class="s3">'LeakyReLU'</span><span class="s2">,</span><span class="s3">'LeakyReLU'</span><span class="s2">,</span><span class="s3">'LeakyReLU'</span><span class="s1">]</span>
<span class="s1">l_dropouts = [</span><span class="s4">0.3</span><span class="s2">, </span><span class="s4">0.2</span><span class="s2">, </span><span class="s4">0.2</span><span class="s1">]</span>
<span class="s1">x_train</span><span class="s2">,</span><span class="s1">x_test</span><span class="s2">,</span><span class="s1">y_train</span><span class="s2">,</span><span class="s1">y_test=split_and_balance(df=train_df</span><span class="s2">,</span>
                                                <span class="s1">augmentation=RandomOverSampler(random_state=</span><span class="s4">17</span><span class="s1">))</span>
<span class="s1">nn_scal=PowerTransformer()</span>
<span class="s1">nn_scal.fit(x_train)</span>

<span class="s1">model = Fc_nn(input_size=x_train.shape[</span><span class="s4">1</span><span class="s1">]</span><span class="s2">, </span><span class="s1">output_size=</span><span class="s4">1</span><span class="s2">, </span><span class="s1">n_layers=</span><span class="s4">3</span><span class="s2">,</span>
              <span class="s1">hidden_sizes=[</span><span class="s4">1120</span><span class="s2">,</span><span class="s4">672</span><span class="s2">,</span><span class="s4">640</span><span class="s1">]</span><span class="s2">,</span><span class="s1">l_activations=l_activations</span><span class="s2">,</span>
              <span class="s1">l_dropouts=l_dropouts).to(device)</span>

<span class="s1">model.load_state_dict(torch.load(</span><span class="s3">'best_trial_st_dict.pth'</span><span class="s2">,</span>
                                 <span class="s1">map_location=torch.device(device)))</span>
<span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">nn_predict(input_data=</span><span class="s2">None,</span><span class="s1">test_target=</span><span class="s2">None,</span><span class="s1">train_data=</span><span class="s2">None,</span>
               <span class="s1">train_target=</span><span class="s2">None,</span><span class="s1">return_report=</span><span class="s2">False,</span>
               <span class="s1">return_prediction=</span><span class="s2">True</span><span class="s1">):</span>
    <span class="s0"># prediction=None</span>
    <span class="s0"># model.eval()</span>
    <span class="s1">predict=model.requires_grad_(</span><span class="s2">False</span><span class="s1">)\</span>
        <span class="s1">(torch.tensor(input_data</span><span class="s2">,</span><span class="s1">dtype=torch.float32)).round().view(-</span><span class="s4">1</span><span class="s1">).numpy()</span>

    <span class="s1">predict[predict&lt;</span><span class="s4">1</span><span class="s1">]=</span><span class="s4">1</span>
    <span class="s1">predict[predict&gt;</span><span class="s4">3</span><span class="s1">]=</span><span class="s4">3</span>
    <span class="s2">if </span><span class="s1">train_data </span><span class="s2">is not None</span><span class="s1">:</span>
        <span class="s1">train_predict=model.requires_grad_(</span><span class="s2">False</span><span class="s1">)\</span>
            <span class="s1">(torch.tensor(train_data</span><span class="s2">,</span><span class="s1">dtype=torch.float32)).round().view(-</span><span class="s4">1</span><span class="s1">).numpy()</span>

        <span class="s1">train_predict[train_predict&lt;</span><span class="s4">1</span><span class="s1">]=</span><span class="s4">1</span>
        <span class="s1">train_predict[train_predict&gt;</span><span class="s4">3</span><span class="s1">]=</span><span class="s4">3</span>

    <span class="s2">if </span><span class="s1">return_report:</span>
        <span class="s1">print(</span><span class="s3">f'test_report:</span><span class="s2">\n{</span><span class="s1">classification_report(predict</span><span class="s2">,</span><span class="s1">test_target)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s1">print(</span><span class="s3">f'accuracy:</span><span class="s2">\n{</span><span class="s1">(predict==test_target).sum()/(test_target.shape[</span><span class="s4">0</span><span class="s1">])</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

        <span class="s2">if </span><span class="s1">train_data </span><span class="s2">is not None</span><span class="s1">:</span>
            <span class="s1">print(</span><span class="s3">f'train_report:</span><span class="s2">\n{</span><span class="s1">classification_report(train_predict</span><span class="s2">,</span><span class="s1">train_target)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">pd.DataFrame.from_dict(classification_report(predict</span><span class="s2">,</span><span class="s1">test_target</span><span class="s2">,</span><span class="s1">output_dict=</span><span class="s2">True</span><span class="s1">))</span>

    <span class="s2">if </span><span class="s1">return_prediction:</span>
        <span class="s2">return </span><span class="s1">predict</span>
<span class="s0">#%% 
</span><span class="s1">x_train</span><span class="s2">,</span><span class="s1">x_test</span><span class="s2">,</span><span class="s1">y_train</span><span class="s2">,</span><span class="s1">y_test=split_and_balance(df=train_df</span><span class="s2">,</span>
                                                <span class="s1">augmentation=RandomOverSampler(random_state=</span><span class="s4">17</span><span class="s1">))</span>

<span class="s1">x_test=nn_scal.transform(x_test)</span>
<span class="s1">nn_report=nn_predict(x_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">,</span><span class="s1">return_prediction=</span><span class="s2">False,</span><span class="s1">return_report=</span><span class="s2">True</span><span class="s1">)</span>

<span class="s2">del </span><span class="s1">x_test</span><span class="s2">, </span><span class="s1">y_test</span><span class="s2">,</span><span class="s1">x_train</span><span class="s2">,</span><span class="s1">y_train</span>
<span class="s0">#%% 
</span><span class="s1">model</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding trained FC_nn to the dictionary** 
 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'FC_nn'</span><span class="s1">]=[nn_report]</span>
<span class="s0">#%% md 
</span><span class="s1"># weighted voting ensemble 
*creating weighted majority votes function* 
</span><span class="s0">#%% 
</span><span class="s2">def </span><span class="s1">voting_ensemble(data=</span><span class="s2">None,</span><span class="s1">target=</span><span class="s2">False,</span><span class="s1">pipe_dict=pipelines_and_scores</span><span class="s2">,</span>
                    <span class="s1">estimators=</span><span class="s2">None,</span><span class="s1">nn_scale=</span><span class="s2">None,</span><span class="s1">weights=</span><span class="s2">False,</span>
                    <span class="s1">weights_method=</span><span class="s3">'precision'</span><span class="s1">):</span>

    <span class="s1">predict_df=pd.DataFrame()</span>
    <span class="s1">weights_df=pd.DataFrame()</span>
    <span class="s1">weighted_predict_df=pd.DataFrame()</span>

    <span class="s2">if </span><span class="s1">estimators </span><span class="s2">is None</span><span class="s1">:</span>
        <span class="s1">estimators=pipe_dict.keys()</span>

    <span class="s2">for </span><span class="s1">i</span><span class="s2">,</span><span class="s1">estimator </span><span class="s2">in </span><span class="s1">enumerate(estimators):</span>

        <span class="s2">if </span><span class="s1">i==</span><span class="s4">0</span><span class="s1">:</span>
            <span class="s1">predict_df=pd.DataFrame({str(estimator):</span>
                                         <span class="s1">pipelines_and_scores[estimator][</span><span class="s4">0</span><span class="s1">].predict(data)})</span>
            <span class="s2">if </span><span class="s1">weights:</span>
                <span class="s1">weights_df=pd.DataFrame({str(estimator):</span>
                                             <span class="s1">pipelines_and_scores[estimator][-</span><span class="s4">1</span><span class="s1">].T[weights_method][:</span><span class="s4">3</span><span class="s1">]})</span>

        <span class="s2">elif </span><span class="s1">estimator==</span><span class="s3">'FC_nn'</span><span class="s1">:</span>
            <span class="s1">predict_df[</span><span class="s3">'FC_nn'</span><span class="s1">]=nn_predict(nn_scale.transform(data)</span><span class="s2">,</span>
                                           <span class="s1">return_prediction=</span><span class="s2">True,</span><span class="s1">return_report=</span><span class="s2">False</span><span class="s1">)</span>

            <span class="s2">if </span><span class="s1">weights:</span>
                <span class="s1">weights_df[</span><span class="s3">'FC_nn'</span><span class="s1">]=pipelines_and_scores[</span><span class="s3">'FC_nn'</span><span class="s1">][-</span><span class="s4">1</span><span class="s1">].T[weights_method][:</span><span class="s4">3</span><span class="s1">].to_list()</span>

        <span class="s2">else</span><span class="s1">:</span>
            <span class="s1">predict_df[str(estimator)]=pipelines_and_scores[estimator][</span><span class="s4">0</span><span class="s1">].predict(data)</span>
            <span class="s2">if </span><span class="s1">estimator==</span><span class="s3">'XGBoost'</span><span class="s1">:</span>
                <span class="s1">predict_df[str(estimator)]+=</span><span class="s4">1</span>

            <span class="s2">if </span><span class="s1">weights:</span>
                <span class="s1">weights_df[str(estimator)]=pipelines_and_scores[estimator][-</span><span class="s4">1</span><span class="s1">].T[weights_method][:</span><span class="s4">3</span><span class="s1">]</span>

    <span class="s2">if </span><span class="s1">weights:</span>
        <span class="s2">for </span><span class="s1">n_m</span><span class="s2">,</span><span class="s1">model_algo </span><span class="s2">in </span><span class="s1">enumerate(predict_df):</span>
            <span class="s2">if </span><span class="s1">n_m==</span><span class="s4">0</span><span class="s1">:</span>
                <span class="s1">weighted_predict_df=pd.get_dummies(predict_df</span>
                                                   <span class="s1">.loc[:</span><span class="s2">,</span><span class="s1">model_algo])\</span>
                                    <span class="s1">*weights_df[model_algo][-</span><span class="s4">1</span><span class="s1">].tolist()</span>
            <span class="s2">else</span><span class="s1">:</span>
                <span class="s1">weighted_predict_df+=pd.get_dummies(predict_df</span>
                                                    <span class="s1">.loc[:</span><span class="s2">,</span><span class="s1">model_algo])\</span>
                                     <span class="s1">*weights_df[model_algo][-</span><span class="s4">1</span><span class="s1">].tolist()</span>

    <span class="s2">if </span><span class="s1">weights:</span>
        <span class="s1">weighted_prediction=np.argmax(weighted_predict_df.to_numpy()</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s1">)+</span><span class="s4">1</span>

        <span class="s2">if </span><span class="s1">target </span><span class="s2">is not False</span><span class="s1">:</span>
            <span class="s1">print(</span><span class="s3">f'Weighted (by </span><span class="s2">{</span><span class="s1">weights_method</span><span class="s2">}</span><span class="s3">) prediction accuracy: '</span>
                  <span class="s3">f'</span><span class="s2">{</span><span class="s1">(weighted_prediction==target).sum()/target.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}\n</span><span class="s3">'</span>
                  <span class="s3">f'</span><span class="s2">{</span><span class="s1">classification_report(weighted_prediction</span><span class="s2">,</span><span class="s1">target)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

        <span class="s2">return </span><span class="s1">weighted_prediction</span>

    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">unweighted_predictions=predict_df.mode(axis=</span><span class="s4">1</span><span class="s1">)[</span><span class="s4">0</span><span class="s1">].to_numpy()</span>
        <span class="s1">print(</span><span class="s3">f'Unweighted prediction accuracy: </span><span class="s2">{</span><span class="s1">(unweighted_predictions==target).sum()/target.shape[</span><span class="s4">0</span><span class="s1">]</span><span class="s2">}</span><span class="s3">'</span>
              <span class="s3">f'</span><span class="s2">\n{</span><span class="s1">classification_report(unweighted_predictions</span><span class="s2">,</span><span class="s1">target)</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>
        <span class="s2">return </span><span class="s1">pd.DataFrame(unweighted_predictions).replace(num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">])</span>
<span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">'XGBoost'</span><span class="s1">][</span><span class="s4">1</span><span class="s1">].rename(columns={</span><span class="s3">'0'</span><span class="s1">:</span><span class="s3">'1'</span><span class="s2">,</span><span class="s3">'1'</span><span class="s1">:</span><span class="s3">'2'</span><span class="s2">,</span><span class="s3">'2'</span><span class="s1">:</span><span class="s3">'3'</span><span class="s1">}</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">**weighted voting ensemble** 
</span><span class="s0">#%% 
</span><span class="s1">estim=[</span><span class="s3">'RandomForestClassifier'</span><span class="s2">,</span><span class="s3">'XGBoost'</span><span class="s2">,</span><span class="s3">'Knn'</span><span class="s2">,</span><span class="s3">'HistGdb'</span><span class="s1">]</span>
<span class="s1">weight_method=</span><span class="s3">'f1-score'</span>
<span class="s1">x_train</span><span class="s2">,</span><span class="s1">x_test</span><span class="s2">,</span><span class="s1">y_train</span><span class="s2">,</span><span class="s1">y_test=split_and_balance(df=train_df</span><span class="s2">,</span><span class="s1">augmentation=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s1">weighted_pre=voting_ensemble(data=x_test</span><span class="s2">,</span><span class="s1">target=y_test</span><span class="s2">,</span><span class="s1">pipe_dict=pipelines_and_scores</span><span class="s2">,</span>
                             <span class="s1">estimators=estim</span><span class="s2">,</span><span class="s1">nn_scale=nn_scal</span><span class="s2">,</span><span class="s1">weights=</span><span class="s2">True,</span>
                             <span class="s1">weights_method=weight_method)</span>
<span class="s0">#%% md 
</span>
<span class="s0">#%% md 
</span><span class="s1">**Adding voting ensemble to the dictionary** 
 
</span><span class="s0">#%% 
</span><span class="s1">pipelines_and_scores[</span><span class="s3">f'Weighted(</span><span class="s2">{</span><span class="s1">weight_method</span><span class="s2">}</span><span class="s3">)</span><span class="s2">\n</span><span class="s3">voting ensemble</span><span class="s2">\n{</span><span class="s1">estim</span><span class="s2">}</span><span class="s3">'</span><span class="s1">]=\</span>
    <span class="s1">[pd.DataFrame.from_dict(classification_report(weighted_pre</span><span class="s2">,</span><span class="s1">y_test</span><span class="s2">,</span><span class="s1">output_dict=</span><span class="s2">True</span><span class="s1">))]</span>
<span class="s0">#%% md 
</span><span class="s1"># Models scores 
</span><span class="s0">#%% 
</span><span class="s2">for </span><span class="s1">t</span><span class="s2">,</span><span class="s1">model </span><span class="s2">in </span><span class="s1">enumerate(pipelines_and_scores.keys()):</span>
    <span class="s2">if </span><span class="s1">t==</span><span class="s4">0</span><span class="s1">:</span>
        <span class="s1">models_accuracy=pd.DataFrame({model:[pipelines_and_scores[model][-</span><span class="s4">1</span><span class="s1">][</span><span class="s3">'accuracy'</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]]})</span>
    <span class="s2">else</span><span class="s1">:</span>
        <span class="s1">models_accuracy[model]=pipelines_and_scores[model][-</span><span class="s4">1</span><span class="s1">][</span><span class="s3">'accuracy'</span><span class="s1">][</span><span class="s4">0</span><span class="s1">]</span>
<span class="s1">plt.figure(figsize=(</span><span class="s4">10</span><span class="s2">,</span><span class="s4">5</span><span class="s1">))</span>
<span class="s1">sns.barplot(data=models_accuracy.T.sort_values([</span><span class="s4">0</span><span class="s1">]</span><span class="s2">,</span><span class="s1">ascending=</span><span class="s2">False</span><span class="s1">).T</span><span class="s2">,</span><span class="s1">width=</span><span class="s4">1</span><span class="s1">)</span>
<span class="s1">plt.title(</span><span class="s3">&quot;Models Accuracy&quot;</span><span class="s1">)</span>
<span class="s0">#%% 
</span><span class="s2">for </span><span class="s1">algo </span><span class="s2">in </span><span class="s1">pipelines_and_scores.keys():</span>
    <span class="s1">print(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">algo</span><span class="s2">} </span><span class="s3">report:</span><span class="s2">\n{</span><span class="s1">pipelines_and_scores[algo][-</span><span class="s4">1</span><span class="s1">].T</span><span class="s2">}\n\n</span><span class="s3">'</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Confusion matrix 
</span><span class="s0">#%% 
</span><span class="s1">y=y_test.replace(num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">])</span>
<span class="s1">y_p=pd.DataFrame(weighted_pre).replace(num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">])</span>
<span class="s1">conf_metrix=confusion_matrix(y</span><span class="s2">,</span><span class="s1">y_p)</span>
<span class="s1">con=ConfusionMatrixDisplay(conf_metrix</span><span class="s2">, </span><span class="s1">display_labels=[</span><span class="s3">'Good'</span><span class="s2">,</span><span class="s3">'Poor'</span><span class="s2">,</span><span class="s3">'Standard'</span><span class="s1">])</span>
<span class="s1">con=con.plot(cmap=plt.cm.Blues</span><span class="s2">,</span><span class="s1">values_format=</span><span class="s3">'g'</span><span class="s1">)</span>
<span class="s1">plt.grid(</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1"># Adjust new data for prediction. 
</span><span class="s0">#%% 
</span><span class="s1">test_path = </span><span class="s3">r'test.csv'</span>
<span class="s1">test_df = pd.read_csv(test_path)</span>
<span class="s0">#%% 
</span><span class="s1">obj_to_num_dict[</span><span class="s3">'Month'</span><span class="s1">].update({</span><span class="s3">'September'</span><span class="s1">:</span><span class="s4">9</span><span class="s2">,</span>
                                 <span class="s3">'October'</span><span class="s1">:</span><span class="s4">10</span><span class="s2">,</span>
                                 <span class="s3">'November'</span><span class="s1">:</span><span class="s4">11</span><span class="s2">,</span>
                                 <span class="s3">'December'</span><span class="s1">:</span><span class="s4">12</span><span class="s1">})</span>

<span class="s2">def </span><span class="s1">test_data_adjust(new_data):</span>

    <span class="s2">if not </span><span class="s1">isinstance(new_data</span><span class="s2">,</span><span class="s1">(pd.DataFrame</span><span class="s2">,</span><span class="s1">pd.Series)):</span>
        <span class="s2">raise </span><span class="s1">TypeError(</span><span class="s3">f'</span><span class="s2">{</span><span class="s1">type(new_data)</span><span class="s2">} </span><span class="s3">is not valid. valid classes:'</span>
                        <span class="s3">f' </span><span class="s2">{</span><span class="s1">pd.DataFrame</span><span class="s2">} </span><span class="s3">or </span><span class="s2">{</span><span class="s1">pd.Series</span><span class="s2">}</span><span class="s3">'</span><span class="s1">)</span>

    <span class="s1">new_data.drop([</span><span class="s3">'ID'</span><span class="s2">,</span><span class="s3">'Name'</span><span class="s2">,</span><span class="s3">'SSN'</span><span class="s2">,</span><span class="s3">'Customer_ID'</span><span class="s1">]</span><span class="s2">,</span><span class="s1">axis=</span><span class="s4">1</span><span class="s2">,</span><span class="s1">inplace=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s1">set_numeric_columns(features=mix_type_num_col</span><span class="s2">,</span><span class="s1">df=new_data)</span>
    <span class="s1">replace_invalid_2_nan(new_data)</span>
    <span class="s1">new_data[</span><span class="s3">'Credit_History_Age'</span><span class="s1">]=convert_str_num(</span><span class="s3">'Credit_History_Age'</span><span class="s2">,</span>
                                                   <span class="s1">[</span><span class="s4">0</span><span class="s2">,</span><span class="s4">3</span><span class="s1">]</span><span class="s2">,</span><span class="s1">[</span><span class="s4">12</span><span class="s2">,</span><span class="s4">1</span><span class="s1">]</span><span class="s2">,</span><span class="s1">df=new_data)</span>

    <span class="s1">new_data.Type_of_Loan=new_data.Type_of_Loan.str.replace(</span><span class="s3">'and'</span><span class="s2">,</span><span class="s3">''</span><span class="s1">)</span>
    <span class="s1">new_data=convert_loans_type(df=new_data)</span>

    <span class="s2">for </span><span class="s1">item </span><span class="s2">in </span><span class="s1">list(obj_to_num_dict.items())[:-</span><span class="s4">1</span><span class="s1">]:</span>
        <span class="s1">new_data[item[</span><span class="s4">0</span><span class="s1">]]=new_data[item[</span><span class="s4">0</span><span class="s1">]].replace(item[</span><span class="s4">1</span><span class="s1">])</span>
        <span class="s1">new_data.dropna(inplace=</span><span class="s2">True</span><span class="s1">)</span>

    <span class="s2">return </span><span class="s1">new_data</span>

<span class="s1">test_df=test_data_adjust(test_df)</span>
<span class="s0">#%% md 
</span><span class="s1"># Test data predictions 
</span><span class="s0">#%% 
</span><span class="s1">test_predict=voting_ensemble(data=test_df[features_order.drop(</span><span class="s3">'Credit_Score'</span><span class="s1">)]</span><span class="s2">,</span>
                             <span class="s1">pipe_dict=pipelines_and_scores</span><span class="s2">,</span><span class="s1">weights=</span><span class="s2">True,</span>
                             <span class="s1">estimators=[</span><span class="s3">'RandomForestClassifier'</span><span class="s2">,</span><span class="s3">'XGBoost'</span><span class="s2">,</span><span class="s3">'Knn'</span><span class="s2">,</span><span class="s3">'HistGdb'</span><span class="s1">])</span>

<span class="s1">test_predict=pd.DataFrame(test_predict).replace(num_to_obj_dict[</span><span class="s3">'Credit_Score'</span><span class="s1">])</span>
<span class="s1">test_predict.head()</span>
<span class="s0">#%% 
</span><span class="s1">target_ratio(test_predict</span><span class="s2">,</span><span class="s1">target=</span><span class="s2">False</span><span class="s1">)</span>
<span class="s0">#%% md 
</span><span class="s1">*P.S. I think that banks check the customer's history four months back-&gt;if that is the case soo the right way to solve that problem is to build a recurrent model e.g. RNN|LSTM|GRO -&gt; many(4) to one.*</span></pre>
</body>
</html>